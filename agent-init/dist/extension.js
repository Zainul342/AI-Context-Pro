/******/ (() => { // webpackBootstrap
/******/ 	"use strict";
/******/ 	var __webpack_modules__ = ([
/* 0 */,
/* 1 */
/***/ ((module) => {

module.exports = require("vscode");

/***/ }),
/* 2 */
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.WatcherService = void 0;
const vscode = __webpack_require__(1);
const config_1 = __webpack_require__(3);
class WatcherService {
    constructor() {
        // Initialize watcher
    }
    /**
     * Checks if the workspace needs initialization.
     * @param folder The workspace folder to check.
     * @returns true if standards are missing, false if they exist.
     */
    async needsInitialization(folder) {
        const config = config_1.ConfigManager.getConfiguration();
        if (!config.checkOnStartup) {
            return false;
        }
        const hasAgentDir = await this.pathExists(folder.uri, '.agent');
        const hasCursorRules = await this.pathExists(folder.uri, '.cursorrules');
        // Needs init if EITHER is missing (for now, stricter check)
        // Or maybe just if .cursorrules is missing? 
        // Let's require BOTH for a "complete" standard.
        return !(hasAgentDir && hasCursorRules);
    }
    async pathExists(root, pathFragment) {
        try {
            const uri = vscode.Uri.joinPath(root, pathFragment);
            await vscode.workspace.fs.stat(uri);
            return true;
        }
        catch {
            return false;
        }
    }
    watch(context, callback) {
        // 1. Check on startup
        if (vscode.workspace.workspaceFolders) {
            vscode.workspace.workspaceFolders.forEach(folder => {
                this.needsInitialization(folder).then(needsInit => {
                    if (needsInit) {
                        callback(folder);
                    }
                });
            });
        }
        // 2. Watch for new folders
        context.subscriptions.push(vscode.workspace.onDidChangeWorkspaceFolders(event => {
            event.added.forEach(folder => {
                this.needsInitialization(folder).then(needsInit => {
                    if (needsInit) {
                        callback(folder);
                    }
                });
            });
        }));
    }
}
exports.WatcherService = WatcherService;


/***/ }),
/* 3 */
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConfigManager = void 0;
const vscode = __webpack_require__(1);
class ConfigManager {
    static getConfiguration() {
        const config = vscode.workspace.getConfiguration('agentInit');
        return {
            autoInit: config.get('autoInit', false),
            checkOnStartup: config.get('checkOnStartup', true),
            watchForDrift: config.get('watchForDrift', false)
        };
    }
}
exports.ConfigManager = ConfigManager;


/***/ }),
/* 4 */
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.UIController = void 0;
const vscode = __webpack_require__(1);
class UIController {
    constructor(context) {
        this.context = context;
    }
    /**
     * Shows a prompt to the user to initialize the project.
     * @returns true if the user clicked "Initialize", false otherwise.
     */
    async showInitializePrompt() {
        if (UIController.isPromptOpen) {
            return false;
        }
        UIController.isPromptOpen = true;
        try {
            // Check if user ignored this workspace previously
            const isIgnored = this.context.workspaceState.get('agentInit.ignored', false);
            if (isIgnored) {
                return false;
            }
            // Small delay to ensure UI is ready and prevent instant-flash on startup
            await new Promise(resolve => setTimeout(resolve, 500));
            const selection = await vscode.window.showInformationMessage('Agent Init: AI Standards missing in this workspace. Initialize now?', 'Initialize', 'Ignore');
            if (selection === 'Initialize') {
                return true;
            }
            if (selection === 'Ignore') {
                await this.context.workspaceState.update('agentInit.ignored', true);
            }
            return false;
        }
        finally {
            UIController.isPromptOpen = false;
        }
    }
    showSuccessMessage(message) {
        vscode.window.showInformationMessage(message);
    }
    showErrorMessage(message) {
        vscode.window.showErrorMessage(message);
    }
}
exports.UIController = UIController;
UIController.isPromptOpen = false;


/***/ }),
/* 5 */
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.GitHubClient = void 0;
const fallback_data_1 = __webpack_require__(6);
class GitHubClient {
    constructor() {
        this.baseUrl = 'https://raw.githubusercontent.com';
    }
    /**
     * Fetches templates from the remote repository with concurrency control.
     * @param source The source repository details.
     * @param onProgress Optional callback for progress updates.
     */
    async fetchTemplate(source, onFetchResult) {
        const files = new Map();
        const concurrencyLimit = 5;
        const queue = [...fallback_data_1.filesToFetch];
        const results = [];
        // Simple concurrency limiter
        const next = async () => {
            if (queue.length === 0)
                return;
            const filePath = queue.shift();
            const url = `${this.baseUrl}/${source.owner}/${source.repo}/${source.branch}/${filePath}`;
            try {
                const content = await this.fetchUrl(url);
                files.set(filePath, content);
                onFetchResult?.({ path: filePath, status: 'remote' });
            }
            catch (error) {
                // Fallback mechanism
                if (fallback_data_1.FALLBACK_CONTENT[filePath]) {
                    files.set(filePath, fallback_data_1.FALLBACK_CONTENT[filePath]);
                    onFetchResult?.({ path: filePath, status: 'fallback', error: error });
                }
                else {
                    onFetchResult?.({ path: filePath, status: 'failed', error: error });
                    if (filePath === '.cursorrules') {
                        throw new Error(`Critical file missing: ${filePath}`);
                    }
                }
            }
            await next(); // Process next item
        };
        // Start initial batch
        for (let i = 0; i < Math.min(concurrencyLimit, fallback_data_1.filesToFetch.length); i++) {
            results.push(next());
        }
        await Promise.all(results);
        return {
            files,
            version: 'latest'
        };
    }
    async fetchUrl(url) {
        // Add timeout to prevent hanging requests
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 5000); // 5s timeout
        try {
            const response = await fetch(url, { signal: controller.signal });
            if (!response.ok) {
                throw new Error(`HTTP ${response.status}`);
            }
            return await response.text();
        }
        finally {
            clearTimeout(timeoutId);
        }
    }
}
exports.GitHubClient = GitHubClient;


/***/ }),
/* 6 */
/***/ ((__unused_webpack_module, exports) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.FALLBACK_CONTENT = exports.filesToFetch = void 0;
// AUTOMATICALLY GENERATED - DO NOT EDIT MANUALLY
exports.filesToFetch = [
    ".agent/rules/api-design-principles.md",
    ".agent/rules/architectural-pattern.md",
    ".agent/rules/avoid-circular-dependencies.md",
    ".agent/rules/code-completion-mandate.md",
    ".agent/rules/code-idioms-and-conventions.md",
    ".agent/rules/code-organization-principles.md",
    ".agent/rules/command-execution-principles.md",
    ".agent/rules/concurrency-and-threading-mandate.md",
    ".agent/rules/concurrency-and-threading-principles.md",
    ".agent/rules/configuration-management-principles.md",
    ".agent/rules/core-design-principles.md",
    ".agent/rules/data-serialization-and-interchange-principles.md",
    ".agent/rules/dependency-management-principles.md",
    ".agent/rules/documentation-principles.md",
    ".agent/rules/error-handling-principles.md",
    ".agent/rules/logging-and-observability-mandate.md",
    ".agent/rules/logging-and-observability-principles.md",
    ".agent/rules/performance-optimization-principles.md",
    ".agent/rules/project-structure.md",
    ".agent/rules/resources-and-memory-management-principles.md",
    ".agent/rules/rugged-software-constitution.md",
    ".agent/rules/security-mandate.md",
    ".agent/rules/security-principles.md",
    ".agent/rules/testing-strategy.md",
    ".agent/workflows/1-research.md",
    ".agent/workflows/2-implement.md",
    ".agent/workflows/3-integrate.md",
    ".agent/workflows/4-verify.md",
    ".agent/workflows/5-commit.md",
    ".agent/workflows/e2e-test.md",
    ".agent/workflows/orchestrator.md",
    ".agent/skills/debugging-protocol/SKILL.md",
    ".agent/skills/frontend-design/SKILL.md",
    ".agent/skills/sequential-thinking/SKILL.md"
];
exports.FALLBACK_CONTENT = {
    ".agent/rules/api-design-principles.md": "---\\ntrigger: model_decision\\ndescription: When implementing REST/HTTP APIs (endpoints, handlers, middleware, or response formatting)\\n---\\n\\n## API Design Principles (The Funny Edition)\\n\\n### RESTful API Standards\\n\\n**Resource-Based URLs:**\\n\\n- Use plural nouns: `/api/{version}/users` (because users satisfy the need for company). \\n- Hierarchical relationships: `/api/{version}/users/:userId/orders` (order matters, chaos does not). \\n- **AVOID VERBS IN URLS**: `/api/{version}/getUser` ❌ -> If you use verbs, a kitten cries somewhere. `/api/{version}/users/:id` ✅\\n\\n**HTTP Methods (The Sacred Verbs):**\\n\\n- **GET**: Read (safe, idempotent, like looking but not touching).\\n- **POST**: Create (not idempotent, creates life... or resources).\\n- **PUT**: Replace (idempotent, swap it out like Indiana Jones).\\n- **PATCH**: Partial update (idempotent, fix it with duct tape).\\n- **DELETE**: Remove (idempotent, maximize entropy).\\n\\n**Versioning:**\\n\\n- URL path versioning: `/api/v1/users` (because v0 was a disaster).\\n\\n**Status Codes (The Mood Ring):**\\n\\n- **200 OK**: Everything is fine.\\n- **201 Created**: It lives!\\n- **400 Bad Request**: You messed up.\\n- **401 Unauthorized**: Who are you?\\n- **403 Forbidden**: You shall not pass!\\n- **404 Not Found**: *Tumbleweed rolls by*\\n- **418 I'm a teapot**: Highly recommended for coffee endpoints.\\n- **500 Internal Server Error**: I messed up.\\n",
    ".agent/rules/architectural-pattern.md": "---\ntrigger: always_on\n---\n\n## Architectural Patterns - Testability-First Design\n\n### Core Principle\nAll code must be independently testable without running the full application or external infrastructure.\n\n### Universal Architecture Rules\n\n#### Rule 1: I/O Isolation\n**Problem:** Tightly coupled I/O makes tests slow, flaky, and environment-dependent.\n\n**Solution:** Abstract all I/O behind interfaces/contracts:\n- Database queries\n- HTTP calls (to external APIs)\n- File system operations\n- Time/randomness (for determinism)\n- Message queues\n\n**Implementation Discovery:**\n1. Search for existing abstraction patterns: `find_symbol(\"Interface\")`, `find_symbol(\"Mock\")`, `find_symbol(\"Repository\")`\n2. Match the style (interface in Go, Protocol in Python, interface in TypeScript)\n3. Implement production adapter AND test adapter\n\n**Example (Go):**\n\n```Go\n\n// Contract\ntype UserStore interface {\n  Create(ctx context.Context, user User) error\n  GetByEmail(ctx context.Context, email string) (*User, error)\n}\n\n// Production adapter\ntype PostgresUserStore struct { /* ... */ }\n\n// Test adapter\ntype MockUserStore struct { /* ... */ }\n```\n\n**Example (TypeScript/Vue):**\n```typescript\n\n// Contract (service layer)\nexport interface TaskAPI {\n  createTask(title: string): Promise<Task>;\n  getTasks(): Promise<Task[]>;\n}\n\n// Production adapter\nexport class BackendTaskAPI implements TaskAPI { /* ... */ }\n\n// Test adapter (vi.mock or manual)\nexport class MockTaskAPI implements TaskAPI { /* ... */ }\n\n```\n\n#### Rule 2: Pure Business Logic\n**Problem:** Business rules mixed with I/O are impossible to test without infrastructure.\n\n**Solution:** Extract calculations, validations, transformations into pure functions:\n- Input → Output, no side effects\n- Deterministic: same input = same output\n- No I/O inside business rules\n\n**Examples:**\n```\n\n// ✅ Pure function - easy to test\nfunc calculateDiscount(items []Item, coupon Coupon) (float64, error) {\n// Pure calculation, returns value\n}\n\n// ❌ Impure - database call inside\nfunc calculateDiscount(ctx context.Context, items []Item, coupon Coupon) (float64, error) {\nvalidCoupon, err := db.GetCoupon(ctx, coupon.ID) // NO!\n}\n\n```\n\n**Correct approach:**\n```\n\n// 1. Fetch dependencies first (in handler/service)\nvalidCoupon, err := store.GetCoupon(ctx, coupon.ID)\n\n// 2. Pass to pure logic\ndiscount, err := calculateDiscount(items, validCoupon)\n\n// 3. Persist result\nerr = store.SaveOrder(ctx, order)\n\n```\n\n#### Rule 3: Dependency Direction\n**Principle:** Dependencies point inward toward business logic.\n\n```\n\n┌──────────────────────────────────────┐\n│  Infrastructure Layer                │\n│  (DB, HTTP, Files, External APIs)    │\n│                                      │\n│  Depends on ↓                        │\n└──────────────────────────────────────┘\n↓\n┌──────────────────────────────────────┐\n│  Contracts/Interfaces Layer          │\n│  (Abstract ports - no implementation)│\n│                                      │\n│  Depends on ↓                        │\n└──────────────────────────────────────┘\n↓\n┌──────────────────────────────────────┐\n│  Business Logic Layer                │\n│  (Pure functions, domain rules)      │\n│  NO dependencies on infrastructure   │\n└──────────────────────────────────────┘\n\n```\n\n**Never:**\n- Business logic imports database driver\n- Domain entities import HTTP framework\n- Core calculations import config files\n\n**Always:**\n- Infrastructure implements interfaces defined by business layer\n- Business logic receives dependencies via injection\n\n### Pattern Discovery Protocol\n\n**Before implementing ANY feature:**\n\n1. **Search existing patterns** (MANDATORY):\n```\n\nfind_symbol(\"Interface\") OR find_symbol(\"Repository\") OR find_symbol(\"Service\")\n\n```\n\n2. **Examine 3 existing modules** for consistency:\n- How do they handle database access?\n- Where are pure functions vs I/O operations?\n- What testing patterns exist?\n\n3. **Document pattern** (>80% consistency required):\n- \"Following pattern from [task, user, auth] modules\"\n- \"X/Y modules use interface-based stores\"\n- \"All tests use [MockStore, vi.mock, TestingPinia] pattern\"\n\n4. **If consistency <80%**: STOP and report fragmentation to human.\n\n### Testing Requirements\n\n**Unit Tests (must run without infrastructure):**\n- Mock all I/O dependencies\n- Test business logic in isolation\n- Fast (<100ms per test)\n- >85% coverage of business paths\n\n**Integration Tests (Testcontainers):**\n- Use real dependencies (via Testcontainers, Firebase emulator)\n- Test adapter implementations\n- Verify contracts work end-to-end\n- Cover all I/O adapters\n\n**Test Organization:**\n- Unit/Integration tests: Co-located with implementation\n- E2E tests: Separate `/e2e` directory\n\n### Language-Specific Idioms\n\n**How to achieve testability in each ecosystem:**\n\n| Language/Framework | Abstraction Pattern | Test Strategy |\n|-------------------|---------------------|---------------|\n| **Go** | Interface types, dependency injection | Table-driven tests, mock implementations |\n| **TypeScript/Vue** | Interface types, service layer, Pinia stores | Vitest with `vi.mock`, `createTestingPinia` |\n| **TypeScript/React** | Interface types, service layer, Context/hooks | Jest with mock factories, React Testing Library |\n| **Python** | `typing.Protocol` or abstract base classes | pytest with fixtures, monkeypatch |\n| **Rust** | Traits, dependency injection | Unit tests with mock implementations, `#[cfg(test)]` |\n| **Flutter/Dart** | Abstract classes, dependency injection | `mockito` package, widget tests |\n\n### Enforcement Checklist\n\nBefore marking code complete, verify:\n- [ ] Can I run unit tests without starting database/external services?\n- [ ] Are all I/O operations behind an abstraction?\n- [ ] Is business logic pure (no side effects)?\n- [ ] Do integration tests exist for all adapters?\n- [ ] Does pattern match existing codebase (>80% consistency)?\n\n### Related Principles\n- Core Design Principles @core-design-principles.md\n- Testing Strategy @testing-strategy.md\n- Avoid Circular Dependencies @avoid-circular-dependencies.md\n- Code Organization Principles @code-organization-principles.md\n- Project Structure @project-structure.md",
    ".agent/rules/avoid-circular-dependencies.md": "---\ntrigger: always_on\n---\n\n## Avoid Circular Dependencies\n\n**Problem:** Module A imports B, B imports A\n\n- Causes build failures, initialization issues  \n- Indicates poor module boundaries\n\n**Solution:**\n\n- Extract shared code to third module  \n- Restructure dependencies (A→C, B→C)  \n- Use dependency injection\n",
    ".agent/rules/code-completion-mandate.md": "---\ntrigger: always_on\n---\n\n## Code Completion Mandate\n\n### Universal Requirement\n\n**Before marking any code task as complete, you MUST run automated quality checks and remediate all issues.**\n\nThis is NOT OPTIONAL. Delivering code without validation violates the Rugged Software Manifesto @rugged-software-manifesto.\n\n### The Completion Checklist\n\nEvery code generation task follows this workflow:\n\n1. **Generate** - Write the code based on requirements\n2. **Validate** - Run language-appropriate quality checks\n3. **Remediate** - Fix all detected issues\n4. **Verify** - Re-run checks to confirm fixes\n5. **Deliver** - Mark task complete only after all checks pass\n\n**Never skip validation \"to save time.\" Validation IS the work.**\n\n### Language-Specific Quality Commands\n\nWhen you complete code, run these commands based on the language:\n\n#### Go\n```bash\n# Format\ngofumpt -l -w .\n\n# Static Analysis\ngo vet ./...\nstaticcheck ./...\n\n# Security\ngosec -quiet ./...\n\n# Tests\ngo test -race ./...\n```\n\n**If any command fails:**\n\n1. Read the error output \n2. Fix the identified issues in the code\n3. Re-run the command\n4. Do not proceed until all pass\n\n#### TypeScript/Vue\n```bash\n# Format & Lint\npnpm run lint --fix\n\n# Type Check\nnpx vue-tsc --noEmit\n\n# Tests\npnpm run test\n```\n\n**If any command fails:**\n\n1. Read the error output\n2. Fix the identified issues\n3. Re-run the command\n4. Do not proceed until all pass",
    ".agent/rules/code-idioms-and-conventions.md": "---\ntrigger: always_on\n---\n\n## Code Idioms and Conventions\n\n### Universal Principle\n\n**Write idiomatic code for the target language:**\n\n- Code should look natural to developers familiar with that language  \n- Follow established community conventions, not personal preferences  \n- Use language built-ins and standard library effectively  \n- Apply language-appropriate patterns (don't force patterns from other languages)\n\n### Idiomatic Code Characteristics\n\n- Leverages language features (don't avoid features unnecessarily)  \n- Follows language naming conventions  \n- Uses appropriate error handling for language (exceptions vs Result types)  \n- Applies established community patterns\n\n### Avoid Cross-Language Anti-Patterns\n\n- ❌ Don't write \"Java in Python\" or \"C in Go\"  \n- ❌ Don't force OOP patterns in functional languages  \n- ❌ Don't avoid language features because they're \"unfamiliar\"  \n- ✅ Learn and apply language-specific idioms\n",
    ".agent/rules/code-organization-principles.md": "---\ntrigger: always_on\n---\n\n## Code Organization Principles\n\n- Generate small, focused functions with clear single purposes (typically 10-50 lines)  \n- Keep cognitive complexity low (cyclomatic complexity < 10 for most functions)  \n- Maintain clear boundaries between different layers (presentation, business logic, data access)  \n- Design for testability from the start, avoiding tight coupling that prevents testing  \n- Apply consistent naming conventions that reveal intent without requiring comments\n\n### Module Boundaries\n**Problem:** Cross-module coupling makes changes ripple across codebase.\n\n**Solution:** Feature-based organization with clear public interfaces:\n- One feature = one directory\n- Each module exposes a public API (exported functions/classes)\n- Internal implementation details are private\n- Cross-module calls only through public API\n\n**Directory Structure (Language-Agnostic):**\n```\n/task\n\n- public_api.{ext}      # Exported interface\n- business.{ext}        # Pure logic\n- store.{ext}           # I/O abstraction (interface)\n- postgres.{ext}        # I/O implementation\n- mock.{ext}            # Test implementation\n- test.{ext}            # Unit tests (mocked I/O)\n- integration.test.{ext} # Integration tests (real I/O)\n```\n\n**Go Example:**\n```\n/apps/backend/task\n\n- task.go               # API endpoints (public)\n- business.go           # Pure domain logic\n- store.go              # interface UserStore\n- postgres.go           # implements UserStore\n- task_test.go          # Unit tests with MockStore\n- task_integration_test.go # Integration test with Testcontainers for real dependency\n```\n\n**Vue Example:**\n```\n/apps/frontend/src/features/task\n\n- index.ts              # Public exports\n- task.service.ts       # Business logic\n- task.api.ts           # interface TaskAPI\n- task.api.backend.ts   # implements TaskAPI\n- task.store.ts         # Pinia store (uses TaskAPI)\n- task.service.spec.ts  # Unit tests (mock API)\n```\n\n### Feature Interaction Patterns\n\n**Direct Import**\n\nWhen a feature needs another feature's capabilities, import its Service directly:\n\n```go\n// In features/order/logic.go\nimport \"yourapp/internal/features/task\"\n\ntype Logic struct {\n    taskService *task.Service  // Direct dependency injection\n}\n\nfunc (l *Logic) CreateOrder(ctx context.Context, req CreateOrderRequest) error {\n    // Use task service directly\n    task, err := l.taskService.GetTask(ctx, req.TaskID)\n    // ... rest of logic\n}\n\n**Rules**\n\n- Only import Service (public API), never internal files like logic.go or storage.go\n- Declare dependency in the dependent feature's Service constructor\n- Wire dependencies in cmd/api/main.go\n\n**Wiring Example**\n```\n// cmd/api/main.go\ntaskService := task.NewService(taskStorage)\norderService := order.NewService(orderStorage, taskService) // Pass task service\n```",
    ".agent/rules/command-execution-principles.md": "---\ntrigger: model_decision\ndescription: When executing external commands, shell scripts, or system processes\n---\n\n## Command Execution Principles\n\n### Security\n\n**Never execute user input directly:**\n\n- ❌ `exec(userInput)`  \n- ❌ `shell(\"rm \" + userFile)`  \n- ✅ Use argument lists, not shell string concatenation  \n- ✅ Validate and sanitize all arguments\n\n**Run with minimum permissions:**\n\n- Never run commands as root/admin without explicit human approval. If elevated permissions are absolutely required, STOP and request authorization.\n- Use least-privilege service accounts\n\n### Portability\n\n**Use language standard library:**\n\n- Avoid shell commands when standard library provides functionality  \n- Example: Use file I/O APIs instead of `cat`, `cp`, `mv`\n\n**Test on all target OS:**\n\n- Windows, Linux, macOS have different commands and behaviors  \n- Use path joining functions (don't concatenate with /)\n\n### Error Handling\n\n**Check exit codes:**\n\n- Non-zero exit code = failure  \n- Capture and log stderr  \n- Set timeouts for long-running commands  \n- Handle \"command not found\" gracefully\n\n### Related Principles\n- Security Mandate @security-mandate.md\n- Security Principles @security-principles.md",
    ".agent/rules/concurrency-and-threading-mandate.md": "---\ntrigger: always_on\n---\n\n## Concurrency and Threading Mandate\n\n### When to Use Concurrency\n\n**I/O-Bound Operations (async/await, event loops):**\n\n- Network requests, file I/O, database queries  \n- Waiting for external responses dominates execution time  \n- Use: Asynchronous I/O, event-driven concurrency, coroutines\n\n**CPU-Bound Operations (threads, parallel processing):**\n\n- Heavy computation, data processing, video encoding  \n- CPU cycles dominate execution time  \n- Use: OS threads, thread pools, parallel workers\n\n**Don't Over-Use Concurrency:**\n\n- Adds significant complexity (race conditions, deadlocks, debugging difficulty)  \n- Use only when there's measurable performance benefit  \n- Profile first, optimize second\n\n### When NOT to Use Concurrency\n- Simple synchronous operations\n- No measurable performance benefit\n- Avoid premature optimization",
    ".agent/rules/concurrency-and-threading-principles.md": "---\ntrigger: model_decision\ndescription: When implementing concurrent, parallel, or multi-threaded code (async/await, threads, goroutines, actors)\n---\n\n## Concurrency Implementation Principles\n\n**1. Avoid Race Conditions**\n\n**What is a race condition:**\n\n- Multiple threads access shared data concurrently  \n- At least one thread writes/modifies the data  \n- No synchronization mechanism in place  \n- Result depends on unpredictable thread execution timing\n\n**Prevention strategies:**\n\n- Synchronization: Locks, mutexes, semaphores  \n- Immutability: Immutable data is thread-safe by default  \n- Message passing: Send data between threads instead of sharing  \n- Thread-local storage: Each thread has its own copy\n\n**Detection:**\n\n- Go: Run with `-race` flag (race detector)  \n- Rust: Miri tool for undefined behavior detection  \n- C/C++: ThreadSanitizer (TSan)  \n- Java: JCStress, FindBugs\n\n**2. Prevent Deadlocks**\n\n**What is a deadlock:**\n\n- Two or more threads waiting for each other indefinitely  \n- Example: Thread A holds Lock 1, waits for Lock 2; Thread B holds Lock 2, waits for Lock 1\n\n**Four conditions (ALL must be true for deadlock):**\n\n1. Mutual exclusion: Resources held exclusively (locks)  \n2. Hold and wait: Holding one resource while waiting for another  \n3. No preemption: Can't force unlock  \n4. Circular wait: A waits for B, B waits for A\n\n**Prevention (break any one condition):**\n\n- Lock ordering: Always acquire locks in same order  \n- Timeout: Use try_lock with timeout, back off and retry  \n- Avoid nested locks: Don't hold multiple locks simultaneously  \n- Use lock-free data structures when possible\n\n**3. Prefer Immutability**\n\n- Immutable data = thread-safe by default (no synchronization needed)  \n- Share immutable data freely between threads  \n- Use immutable data structures where possible (Rust default, functional languages)  \n- If data must change, use message passing instead of shared mutable state\n\n**4. Message Passing Over Shared Memory**\n\n- \"Don't communicate by sharing memory; share memory by communicating\" (Go proverb)  \n- Send data through channels/queues instead of accessing shared memory  \n- Reduces need for locks and synchronization  \n- Easier to reason about and test\n\n**5. Graceful Degradation**\n\n- Handle concurrency errors gracefully (timeouts, retries, circuit breakers)  \n- Don't crash entire application on one thread failure  \n- Use supervisors/monitors for fault tolerance (Erlang/Elixir actor model)  \n- Implement backpressure for producer-consumer scenarios\n\n### Concurrency Models by Use Case\n\n- **I/O-bound:** async/await, event loops, coroutines, green threads  \n- **CPU-bound:** OS threads, thread pools, parallel processing  \n- **Actor model:** Erlang/Elixir actors, Akka (message passing, isolated state)  \n- **CSP (Communicating Sequential Processes):** Go channels, Rust channels\n\n### Testing Concurrent Code\n\n- Write unit tests with controlled concurrency (deterministic execution)  \n- Test timeout scenarios and resource exhaustion  \n- Test thread pool full, queue full scenarios\n\n### Related Principles\n- Resource and Memory Management Principles @resources-and-memory-management-principles.md\n- Error Handling Principles @error-handling-principles.md\n- Testing Strategy @testing-strategy.md",
    ".agent/rules/configuration-management-principles.md": "---\ntrigger: model_decision\ndescription: When working with application configuration, environment variables, settings files, or secrets management\n---\n\n## Configuration Management Principles\n\n### Separation of Configuration and Code\n\n**Configuration:**\n\n- Environment-specific values (URLs, credentials, feature flags, timeouts)  \n- Changes between dev/staging/prod  \n- Can change without code deployment\n\n**Code:**\n\n- Business logic and application behavior  \n- Same across all environments  \n- Requires deployment to change\n\n**Never hardcode configuration in code:**\n\n- ❌ `const DB_URL = \"postgresql://prod-db:5432/myapp\"`  \n- ✅ `const DB_URL = process.env.DATABASE_URL`\n\n### Configuration Validation\n\n**Validate at startup:**\n\n- Check all required configuration is present  \n- Fail fast if required config is missing or invalid  \n- Provide clear error messages for misconfiguration  \n- Example: \"DATABASE_URL environment variable is required\"\n\n**Validation checks:**\n\n- Type (string, number, boolean, enum)  \n- Format (URL, email, file path)  \n- Range (port numbers 1-65535)  \n- Dependencies (if feature X enabled, config Y required)\n\n### Configuration Hierarchy\n\n**Precedence (highest to lowest):**\n\n1. **Command-line arguments:** Override everything (for testing, debugging)  \n2. **Environment variables:** Override config files  \n3. **Config files:** Environment-specific (config.prod.yaml, config.dev.yaml)  \n4. **Defaults:** Reasonable defaults in code (fallback)\n\n**Example:**\n\nDatabase port resolution:\n\n1. Check CLI arg: --db-port=5433\n\n2. Check env var: DB_PORT=5432\n\n3. Check config file: database.port=5432\n\n4. Use default: 5432\n\n### Configuration Organization\n\nHybrid Approach (config files + .env files): define the structure of configuration in config files (e.g. config/database.yaml) and use .env files to inject the secret values.\n\n**.env files:** Description: A file dedicated to a specific environment (development) for production these values comes from secrets/environment platfrom or manager not a physical `.env` file on disk. When to Use: Use this only for secrets (API keys, passwords) and a few environment-specific values (like a server IP). These files except `.env.template` should never be committed to version control (git).\n\n- `.env.template` - Consist of credentials and secrets with blank value (SHOULD commit to git)  \n- `.env.development` - Local development credentials and secrets (SHOULD NOT commit to git)  \n\n**Example `.env.development`:**\n```\nDEV_DB_HOST=123.45.67.89\nDEV_DB_USERNAME=prod_user\nDEV_DB_PASSWORD=a_very_secure_production_password\n```\n\n**Feature files:** Description: Settings are grouped into files based on what they do (database, auth, etc.). This keeps your configuration organized. When to Use: Use this as your primary method for organizing non-secret settings. It’s the best way to keep your configuration clean and scalable as your application grows.\n\n- `config/database.yaml` - Database settings  \n- `config/redis.yaml` - Cache settings  \n- `config/auth.yaml` - Authentication settings\n\n**Example `config/database.yaml`:**\n```\ndefault: &default\n  adapter: postgresql\n  pool: 5\ndevelopment:\n  <<: *default\n  host: localhost\n  database: myapp_dev\n  username: <%= ENV['DEV_DB_USERNAME'] %> # Placeholder for a secret\n  password: <%= ENV['DEV_DB_PASSWORD'] %>\nproduction:\n  <<: *default\n  host: <%= ENV['PROD_DB_HOST'] %>\n  database: myapp_prod\n  username: <%= ENV['PROD_DB_USERNAME'] %>\n  password: <%= ENV['PROD_DB_PASSWORD'] %>\n```\n\n### Related Principles\n- Security Mandate @security-mandate.md\n- Security Principles @security-principles.md\n",
    ".agent/rules/core-design-principles.md": "---\\ntrigger: always_on\\n---\n\n## Core Design Principles (Wait, there are rules?)\\n\\n### SOLID Principles (Not Gas, Not Liquid)\\n\\n**Single Responsibility Principle (SRP):**\\n\\n- A class should have ONE reason to change. If it has two, split it like an atom.\\n- If you need 'and' to describe what a function does, you're doing it wrong.\\n\\n**Open/Closed Principle (OCP):**\\n\\n- Open for extension, closed for modification. Like a good relationship.\\n\\n**Liskov Substitution Principle (LSP):**\\n\\n- If it looks like a duck, quacks like a duck, but needs batteries, you probably violated LSP.\\n\\n**Interface Segregation Principle (ISP):**\\n\\n- Don't force clients to depend on interfaces they don't use. It's rude.\\n\\n**Dependency Inversion Principle (DIP):**\\n\\n- Depend on abstractions, not concretions. High-level modules should not depend on low-level modules. Both should depend upon abstractions. Think 'plug and play', not 'hardwired spaghetti'.\\n\\n### Essential Design Practices\\n\\n**DRY (Don't Repeat Yourself):**\\n\\n- Don't repeat yourself. Don't repeat yourself.\\n- Every piece of knowledge must have a single, authoritative representation within a system.\\n\\n**KISS (Keep It Simple, Stupid):**\\n\\n- Complexity is the enemy. Keep it simple enough for a junior dev to understand at 3 AM.\\n\\n**YAGNI (You Aren't Gonna Need It):**\\n\\n- Don't build it until you need it. Future-proofing is often just procrastination in disguise.\\n",
    ".agent/rules/data-serialization-and-interchange-principles.md": "---\ntrigger: model_decision\ndescription: When serializing, deserializing, or validating data formats (JSON, XML, YAML, Protocol Buffers, MessagePack, etc.)\n---\n\n## Data Serialization and Interchange Principles\n\n### Validate at System Boundaries\n\n**All data entering system must be validated:**\n\n- API requests, file uploads, message queue messages  \n- Validate type, format, range, required fields  \n- Fail fast on invalid data (don't process partially valid data)  \n- Return clear validation errors to client\n\n### Handle Encoding Explicitly\n\n**Default to UTF-8:**\n\n- UTF-8 for all text data (API responses, file contents, database strings)  \n- Specify encoding explicitly when reading/writing files  \n- Handle encoding errors gracefully (replacement characters or error)\n\n**Encoding errors:**\n\n- Invalid UTF-8 sequences (malformed bytes)  \n- Mixing encodings (reading UTF-8 as ISO-8859-1)  \n- Always validate and normalize encoding\n\n### Serialization Format Selection\n\n**JSON:**\n\n- Human-readable, widely supported, language-agnostic  \n- Good for: APIs, configuration files, web applications  \n- Limitations: No binary support, larger size than binary formats\n\n**Protocol Buffers:**\n\n- Compact binary format, fast serialization/deserialization  \n- Schema evolution (backward/forward compatibility)  \n- Good for: Internal microservices, high-throughput systems  \n- Limitations: Not human-readable, requires schema definition\n\n**MessagePack:**\n\n- Binary JSON-like format, faster and more compact than JSON  \n- Good for: Internal APIs, when JSON too slow but readability still desired  \n- Limitations: Less widely supported than JSON\n\n**XML:**\n\n- Verbose, legacy systems, document-oriented  \n- Good for: Enterprise systems, SOAP APIs, RSS/Atom feeds  \n- Limitations: Verbosity, complexity, security issues (XXE attacks)\n\n**YAML:**\n\n- Human-friendly, good for configuration files  \n- Good for: Config files, Infrastructure as Code (Kubernetes, CI/CD)  \n- Limitations: Complex parsing, performance, security issues (arbitrary code execution)\n\n### Security Considerations\n\n**Validate before deserialization:**\n\n- Prevent deserialization attacks (arbitrary code execution)  \n- Set size limits on payloads (prevent memory exhaustion)  \n- Whitelist allowed types/classes for deserialization\n\n**Disable dangerous features:**\n\n- XML: Disable external entity processing (XXE prevention)  \n- YAML: Disable unsafe constructors  \n- Python pickle: Never deserialize untrusted data\n\n### Related Principles\n- Error Handling Principles @error-handling-principles.md\n- Security Mandate @security-mandate.md\n- Security Principles @security-principles.md\n- API Design Principles @api-design-principles.md\n",
    ".agent/rules/dependency-management-principles.md": "---\ntrigger: model_decision\ndescription: When managing project dependencies, configuring package files, or organizing module imports\n---\n\n## Dependency Management Principles\n\n### Version Pinning\n\n**Production:** Pin exact versions (1.2.3, not ^1.2.0)\n\n- Prevents supply chain attacks  \n- Prevents unexpected breakage from patch updates  \n- Ensures reproducible builds\n\n**Use lock files:**\n\n- package-lock.json (Node.js)  \n- Cargo.lock (Rust)  \n- go.sum (Go)  \n- requirements.txt (Python)\n\n### Minimize Dependencies\n\n**Every dependency is a liability:**\n\n- Potential security vulnerability  \n- Increased build time and artifact size  \n- Maintenance burden (updates, compatibility)\n\n**Ask before adding dependency:**\n\n- \"Can I implement this in 50 lines?\"  \n- \"Is this functionality critical?\"  \n- \"Is this dependency actively maintained?\"  \n- \"Is this the latest stable version?\"\n\n### Organize Imports\n\n**Grouping:**\n\n1. Standard library  \n2. External dependencies  \n3. Internal modules\n\n**Sorting:** Alphabetical within groups\n\n**Cleanup:** Remove unused imports (use linter/formatter)",
    ".agent/rules/documentation-principles.md": "---\ntrigger: always_on\n---\n\n## Documentation Principles\n\n### Self-Documenting Code\n\n**Clear naming reduces need for comments:**\n\n- Code shows WHAT is happening  \n- Comments explain WHY it's done this way\n\n**When to comment:**\n\n- Complex business logic deserves explanation  \n- Non-obvious algorithms (explain approach)  \n- Workarounds for bugs (link to issue tracker)  \n- Performance optimizations (explain trade-offs)\n\n### Documentation Levels\n\n1. **Inline comments:** Explain WHY for complex code  \n2. **Function/method docs:** API contract (parameters, returns, errors)  \n3. **Module/package docs:** High-level purpose and usage  \n4. **README:** Setup, usage, examples  \n5. **Architecture docs:** System design, component interactions, use valid mermaid diagram\n",
    ".agent/rules/error-handling-principles.md": "---\ntrigger: model_decision\ndescription: When implementing logging, working with loggers, or setting up observability for operations (API handlers, database queries, background jobs, external API calls)\n---\n\n## Error Handling Principles\n\n**1. Never Fail Silently:**\n\n- All errors must be handled explicitly (no empty catch blocks)  \n- If you catch an error, do something with it (log, return, transform, retry)\n\n**2. Fail Fast:**\n\n- Detect and report errors as early as possible  \n- Validate at system boundaries before processing  \n- Don't process invalid data hoping it'll work out\n\n**3. Provide Context:**\n\n- Include error codes, correlation IDs, actionable messages  \n- Enough information for debugging without exposing sensitive details  \n- Example: \"Database query failed (correlation-id: abc-123)\" not \"SELECT * FROM users WHERE...\"\n\n**4. Separate Concerns:**\n\n- Different handlers for different error types  \n- Business errors ≠ technical errors ≠ security errors\n\n**5. Resource Cleanup:**\n\n- Always clean up in error scenarios (close files, release connections, unlock resources)  \n- Use language-appropriate patterns (defer, finally, RAII, context managers)\n\n**6. No Information Leakage:**\n\n- Sanitize error messages for external consumption  \n- Don't expose stack traces, SQL queries, file paths, internal structure to users  \n- Log full details internally, show generic message externally\n\n### Application Error Object (Internal/Log Format)\n```\n{\n  \"status\": \"error\",\n  \"code\": \"VALIDATION_ERROR\",\n  \"message\": \"User-friendly error message\",\n  \"correlationId\": \"uuid-for-tracking\",\n  \"details\": {\n    \"field\": \"email\",\n    \"issue\": \"Invalid email format\",\n    \"provided\": \"invalid-email\",\n    \"expected\": \"valid email format (user@example.com)\"\n  }\n}\n```\n\n### Error Handling Checklist\n\n- [ ] Are all error paths explicitly handled (no empty catch blocks)?  \n- [ ] Do errors include correlation IDs for debugging?  \n- [ ] Are sensitive details sanitized before returning to client?  \n- [ ] Are resources cleaned up in all error scenarios?  \n- [ ] Are errors logged at appropriate levels (warn for 4xx, error for 5xx)?  \n- [ ] Are error tests written (negative test cases)?  \n- [ ] Is error handling consistent across application?\n\n### Related Principles\n- API Design Principles @api-design-principles.md - API Error Response Format section\n- Logging and Observability Mandate @logging-and-observability-mandate.md\n- Logging and Observability Principles @logging-and-observability-principles.md\n- Security Mandate @security-mandate.md\n- Security Principles @security-principles.md\n- Testing Strategy @testing-strategy.md\n- Concurrency and Threading Mandate @concurrency-and-threading-mandate.md\n- Concurrency and Threading Implementation Principles @concurrency-and-threading-principles.md\n",
    ".agent/rules/logging-and-observability-mandate.md": "---\ntrigger: always_on\n---\n\n## Logging and Observability Mandate\n\n### Universal Requirement: All Operations Must Be Logged\n\n**Every operation entry point MUST include logging. No exceptions.**\n\n**What constitutes an \"operation\" (mandatory logging):**\n- API endpoints and request handlers\n- Background jobs and queue workers\n- Event handlers and message consumers\n- Scheduled tasks and cron jobs\n- CLI commands\n- External service calls (to third-party APIs)\n- Database transactions\n\n**What is NOT an operation (no direct logging):**\n- Pure business logic functions (called within operations)\n- Utility and helper functions\n- Data transformations and validators\n\n**Minimum logging requirement (3 points):**\n1. **Operation start:** Log at entry with context (correlationId, userId, operation name)\n2. **Operation success:** Log completion with duration and result identifiers\n3. **Operation failure:** Log error with full context (correlationId, error details, stack trace)\n\n**Mandatory context in all logs:**\n- `correlationId`: UUID for tracing across services\n- `operation`: Clear operation name (e.g., \"create_order\", \"process_payment\")\n- `duration`: Execution time in milliseconds\n- `userId`: Actor who triggered the operation (when applicable)\n- `error`: Full error context on failures\n\n**Enforcement strategy:**\nPrefer middleware, decorators, or framework interceptors for automatic operation logging rather than manual logging in every handler. This ensures coverage without code duplication.\n\n**When implementing any operation entry point, you MUST add logging before proceeding with implementation.**\n\n### Implementation Guide\n\nFor detailed implementation patterns, see:\n- **Logging and Observability Principles @logging-and-observability-principles.md** - Complete implementation guide including:\n  - Log levels and when to use them\n  - Structured logging patterns\n  - Language-specific implementations (Go, TypeScript, Python)\n  - Security considerations (what never to log)\n  - Performance best practices\n  - Log patterns by operation type\n  - Testing and monitoring integration\n\n### Related Principles\n- Logging and Observability Principles @logging-and-observability-principles.md\n- Error Handling Principles @error-handling-principles.md\n- API Design Principles @api-design-principles.md",
    ".agent/rules/logging-and-observability-principles.md": "---\ntrigger: model_decision\ndescription: When implementing logging, working with loggers, or setting up observability for operations (API handlers, database queries, background jobs, external API calls)\n---\n\n## Logging and Observability Principles\n\n> **⚠️ Prerequisite:** All operations MUST be logged per Logging and Observability Mandate @logging-and-observability-mandate.md. This guide provides implementation details.\n\n### Quick Reference: Mandatory Requirements\n\nBefore diving into implementation details, remember these requirements from Logging and Observability Mandate @logging-and-observability-mandate.md:\n\n✅ **Every operation must log:**\n1. Start (with correlationId, operation name, context)\n2. Success (with duration, result identifiers)\n3. Failure (with error details, stack trace)\n\n✅ **Mandatory fields:** correlationId, operation, duration, userId (when applicable), error (on failure)\n\n✅ **Use middleware/interceptors** for automatic coverage\n\n\n### Logging Standards\n\n#### Log Levels (Standard Priority)\n\nUse consistent log levels across all services:\n\n| Level | When to Use | Examples |\n|-------|-------------|----------|\n| **TRACE** | Extremely detailed diagnostic info | Function entry/exit, variable states (dev only) |\n| **DEBUG** | Detailed flow for debugging | Query execution, cache hits/misses, state transitions |\n| **INFO** | General informational messages | Request started, task created, user logged in |\n| **WARN** | Potentially harmful situations | Deprecated API usage, fallback triggered, retry attempt |\n| **ERROR** | Error events that allow app to continue | Request failed, external API timeout, validation failure |\n| **FATAL** | Severe errors causing shutdown | Database unreachable, critical config missing |\n\n#### Logging Rules\n\n**1. Every request/operation must log:**\n```\n\n// Start of operation\nlog.Info(\"creating task\",\n\"correlationId\", correlationID,\n\"userId\", userID,\n\"title\", task.Title,\n)\n\n// Success\nlog.Info(\"task created successfully\",\n\"correlationId\", correlationID,\n\"taskId\", task.ID,\n\"duration\", time.Since(start),\n)\n\n// Error\nlog.Error(\"failed to create task\",\n\"correlationId\", correlationID,\n\"error\", err,\n\"userId\", userID,\n)\n\n```\n\n**2. Always include context:**\n- `correlationId`: Trace requests across services (UUID)\n- `userId`: Who triggered the action\n- `duration`: Operation timing (milliseconds)\n- `error`: Error details (if failed)\n\n\n**3. Structured logging only** (no string formatting):\n```\n\n// ✅ Structured\nlog.Info(\"user login\", \"userId\", userID, \"ip\", clientIP)\n\n// ❌ String formatting\nlog.Info(fmt.Sprintf(\"User %s logged in from %s\", userID, clientIP))\n\n```\n\n**4. Security - Never log:**\n- Passwords or password hashes\n- API keys or tokens\n- Credit card numbers\n- PII in production logs (email/phone only if necessary and sanitized)\n- Full request/response bodies (unless DEBUG level in non-prod)\n\n**5. Performance - Never log in hot paths:**\n- Inside tight loops\n- Per-item processing in batch operations (use summary instead)\n- Synchronous logging in latency-critical paths\n\n**Best Practice:** \"Use logger middleware redaction (e.g., pino-redact, zap masking) rather than manual string manipulation.\"\n\n#### Language-Specific Implementations\n\n##### Go (using slog standard library)\n```\n\nimport \"log/slog\"\n\n// Configure logger\nlogger := slog.New(slog.NewJSONHandler(os.Stdout, &slog.HandlerOptions{\n  Level: slog.LevelInfo, // Production default\n}))\n\n// Usage\nlogger.Info(\"operation started\",\n  \"correlationId\", correlationID,\n  \"userId\", userID,\n)\n\nlogger.Error(\"operation failed\",\n  \"correlationId\", correlationID,\n  \"error\", err,\n  \"retryCount\", retries,\n)\n\n```\n\n##### TypeScript/Node.js (using pino)\n```\n\nimport pino from 'pino';\n\nconst logger = pino({\n  level: process.env.LOG_LEVEL || 'info',\n});\n\nlogger.info({\n  correlationId,\n  userId,\n  duration: Date.now() - startTime,\n}, 'task created successfully');\n\nlogger.error({\n  correlationId,\n  error: err.message,\n  stack: err.stack,\n}, 'failed to create task');\n\n```\n\n#### Python (using structlog)\n```\n\nimport structlog\n\nlogger = structlog.get_logger()\n\nlogger.info(\"task_created\",\ncorrelation_id=correlation_id,\nuser_id=user_id,\ntask_id=task.id,\n)\n\nlogger.error(\"task_creation_failed\",\ncorrelation_id=correlation_id,\nerror=str(err),\nuser_id=user_id,\n)\n\n```\n\n#### Log Patterns by Operation Type\n\n##### API Request/Response\n```\n\n// Request received\nlog.Info(\"request received\",\n  \"method\", r.Method,\n  \"path\", r.URL.Path,\n  \"correlationId\", correlationID,\n  \"userId\", userID,\n)\n\n// Request completed\nlog.Info(\"request completed\",\n  \"correlationId\", correlationID,\n  \"status\", statusCode,\n  \"duration\", duration,\n)\n\n```\n\n##### Database Operations\n```\n\n// Query start (DEBUG level)\nlog.Debug(\"executing query\",\n  \"correlationId\", correlationID,\n  \"query\", \"SELECT * FROM tasks WHERE user_id = $1\",\n)\n\n// Query success (DEBUG level)\nlog.Debug(\"query completed\",\n  \"correlationId\", correlationID,\n  \"rowsReturned\", len(results),\n  \"duration\", duration,\n)\n\n// Query error (ERROR level)\nlog.Error(\"query failed\",\n  \"correlationId\", correlationID,\n  \"error\", err,\n  \"query\", \"SELECT * FROM tasks WHERE user_id = $1\",\n)\n\n```\n\n##### External API Calls\n```\n\n// Call start\nlog.Info(\"calling external API\",\n  \"correlationId\", correlationID,\n  \"service\", \"email-provider\",\n  \"endpoint\", \"/send\",\n)\n\n// Retry (WARN level)\nlog.Warn(\"retrying external API call\",\n  \"correlationId\", correlationID,\n  \"service\", \"email-provider\",\n  \"attempt\", retryCount,\n  \"error\", err,\n)\n\n// Circuit breaker open (WARN level)\nlog.Warn(\"circuit breaker opened\",\n  \"correlationId\", correlationID,\n  \"service\", \"email-provider\",\n  \"failureCount\", failures,\n)\n\n```\n\n##### Background Jobs\n```\n\n// Job start\nlog.Info(\"job started\",\n  \"jobId\", jobID,\n  \"jobType\", \"email-digest\",\n)\n\n// Progress (INFO level - periodic, not per-item)\nlog.Info(\"job progress\",\n  \"jobId\", jobID,\n  \"processed\", 1000,\n  \"total\", 5000,\n  \"percentComplete\", 20,\n)\n\n// Job complete\nlog.Info(\"job completed\",\n  \"jobId\", jobID,\n  \"duration\", duration,\n  \"itemsProcessed\", count,\n)\n\n```\n\n##### Error Scenarios\n```\n\n// Recoverable error (ERROR level)\nlog.Error(\"validation failed\",\n  \"correlationId\", correlationID,\n  \"userId\", userID,\n  \"error\", \"invalid email format\",\n  \"input\", sanitizedInput, // Sanitized!\n)\n\n// Fatal error (FATAL level)\nlog.Fatal(\"critical dependency unavailable\",\n  \"error\", err,\n  \"dependency\", \"database\",\n  \"action\", \"shutting down\",\n)\n\n```\n\n#### Environment-Specific Configuration\n\n| Environment | Level | Format | Destination |\n|-------------|-------|--------|-------------|\n| **Development** | DEBUG | Pretty (colored) | Console |\n| **Staging** | INFO | JSON | Stdout → CloudWatch/GCP |\n| **Production** | INFO | JSON | Stdout → CloudWatch/GCP |\n\n**Configuration (Go example):**\n```\n\nfunc configureLogger() *slog.Logger {\nvar handler slog.Handler\n\n    level := slog.LevelInfo\n    if os.Getenv(\"ENV\") == \"development\" {\n        level = slog.LevelDebug\n        handler = slog.NewTextHandler(os.Stdout, &slog.HandlerOptions{\n            Level: level,\n        })\n    } else {\n        handler = slog.NewJSONHandler(os.Stdout, &slog.HandlerOptions{\n            Level: level,\n        })\n    }\n    \n    return slog.New(handler)\n    }\n\n```\n\n#### Testing Logs\n\n**Unit tests:** Capture and assert on log output\n```\n\n// Go example\nfunc TestUserLogin(t *testing.T) {\nvar buf bytes.Buffer\nlogger := slog.New(slog.NewJSONHandler(&buf, nil))\n\n    // Test operation\n    service := NewUserService(logger, mockStore)\n    err := service.Login(ctx, email, password)\n    \n    // Assert logs\n    require.NoError(t, err)\n    logs := buf.String()\n    assert.Contains(t, logs, \"user login successful\")\n    assert.Contains(t, logs, email)\n    }\n\n```\n\n#### Monitoring Integration\n\n**Correlation IDs:**\n- Generate at ingress (API gateway, first handler)\n- Propagate through all services\n- Include in all logs, errors, and traces\n- Format: UUID v4\n\n**Log aggregation:**\n- Ship to centralized system (CloudWatch, GCP Logs, Datadog)\n- Index by: correlationId, userId, level, timestamp\n- Alert on ERROR/FATAL patterns\n- Dashboard: request rates, error rates, latency\n\n#### Checklist for Every Feature\n\n- [ ] All public operations log INFO on start\n- [ ] All operations log INFO/ERROR on complete/failure\n- [ ] All logs include correlationId\n- [ ] No sensitive data in logs\n- [ ] Structured logging (key-value pairs)\n- [ ] Appropriate log level used\n- [ ] Error logs include error details\n- [ ] Performance-critical paths use DEBUG level\n\n### Observability Strategy\n\n**Three Pillars:**\n\n1. **Logs:** What happened (events, errors, state changes)  \n2. **Metrics:** How much/how many (quantitative measurements)  \n3. **Traces:** How did it happen (request flow through system)\n\n**Key Metrics:**\n\n- **RED (for services):**  \n    \n  - Rate: Requests per second  \n  - Errors: Error rate/count  \n  - Duration: Latency (p50, p95, p99)\n\n\n- **USE (for resources):**  \n    \n  - Utilization: % resource in use (CPU, memory, disk)  \n  - Saturation: How full (queue depth, wait time)  \n  - Errors: Error count\n\n**Health Checks:**\n\n- `/health`: Simple \"am I alive?\" (process health only)  \n- `/ready`: \"Am I ready to serve?\" (includes dependencies)\n\n### Related Principles\n- Error Handling Principles @error-handling-principles.md\n- Security Mandate @security-mandate.md\n- Security Principles @security-principles.md\n- API Design Principles @api-design-principles.md\n",
    ".agent/rules/performance-optimization-principles.md": "---\ntrigger: model_decision\ndescription: When working on performance optimization, profiling, benchmarking, or performance-critical code paths\n---\n\n## Performance Optimization Principles\n\n### Measure Before Optimizing\n\n**\"Premature optimization is the root of all evil\" - Donald Knuth**\n\n**Process:**\n\n1. **Measure:** Profile to find actual bottlenecks (don't guess)  \n2. **Identify:** Find the 20% of code consuming 80% of resources  \n3. **Optimize:** Improve that specific bottleneck  \n4. **Measure again:** Verify improvement with benchmarks  \n5. **Repeat:** Only if still not meeting performance goals\n\n**Don't optimize:**\n\n- Code that's \"fast enough\" for requirements  \n- Code that's rarely executed  \n- Without measurable performance problem\n\n### Choose Appropriate Data Structures\n\n**Selection matters:**\n\n- Hash map: O(1) lookup, unordered  \n- Array/list: O(1) index access, O(n) search, ordered  \n- Binary tree: O(log n) operations, sorted order  \n- Set: O(1) membership testing, unique elements\n\n**Wrong choice causes performance degradation:**\n\n- Using array for lookups: O(n) when O(1) possible with hash map  \n- Using list for sorted data: O(n log n) sort vs O(log n) tree operations\n\n### Avoid Premature Abstraction\n\n**Abstraction has costs:**\n\n- Runtime overhead (indirection, virtual dispatch, dynamic resolution)  \n- Cognitive overhead (understanding layers of abstraction)  \n- Maintenance overhead (changes ripple through abstractions)\n\n**Start concrete, abstract when pattern emerges:**\n\n- Write straightforward code first  \n- Identify duplication and common patterns  \n- Abstract only when there's clear benefit  \n- Don't add \"for future flexibility\" without evidence\n\n### Optimization Techniques\n\n**Caching:**\n\n- Store expensive computation results  \n- Cache database queries, API responses, rendered templates  \n- Use appropriate cache invalidation strategy  \n- Set TTL (time-to-live) for cache entries\n\n**Lazy Loading:**\n\n- Compute only when needed  \n- Load data on-demand, not upfront  \n- Defer expensive operations until required\n\n**Batching:**\n\n- Process multiple items together  \n- Batch database queries (N queries → 1 query)  \n- Batch API requests where possible\n\n**Async I/O:**\n\n- Don't block on I/O operations  \n- Use async/await for concurrent I/O  \n- Process multiple I/O operations in parallel\n\n**Connection Pooling:**\n\n- Reuse expensive resources (database connections, HTTP connections)  \n- See \"Resource and Memory Management Principles\"\n",
    ".agent/rules/project-structure.md": "---\ntrigger: always_on\n---\n\n## Project Structure\n\n**Project Structure Philosophy:**\n\n- **Organize by FEATURE, not by technical layer**  \n- Each feature is a vertical slice\n- Enables modular growth, clear boundaries, and independent deployability  \n\n**Universal Rule: Context → Feature → Layer**\n\n**1. Level 1: Repository Scope:** Root contains `apps/` grouping distinct applications (e.g., `apps/backend`, `apps/frontend`).\n\n**2. Level 2: Feature Organization**\n   - **Rule:** Divide application into vertical business slices (e.g., `user/`, `order/`, `payment/`).\n   - **Anti-Pattern:** Do NOT organize by technical layer (e.g., `controllers/`, `models/`, `services/`) at the top level.\n\n### Layout Examples\n\n**Monorepo Layout (Multi-Stack):**\nUse this structure when managing monolithic full-stack applications with backend, frontend, mobile in a single repository.\n\n**Clear Boundaries:** Backend business logic is isolated from Frontend UI logic, even if they share the same repo\n\n```    \n  apps/\n    backend/                          # Backend application source code\n      cmd/\n        api/\n          main.go                     # Entry point: Wires dependencies, router, starts server  \n    internal/                         # Private application code\n      platform/                       # Foundational technical concerns (The \"Framework\")\n        database/                     # DB connection logic\n        server/                       # HTTP server setup (Router, Middleware)\n        logger/                       # Structured logging setup\n      features/                       # Business Features (Vertical Slices)\n        task/                         # Task management  \n          # --- Interface Definition ---\n          service.go                  # The public API of this feature (Service struct)\n      \n          # --- Delivery (HTTP) ---\n          handler.go                  # HTTP Handlers\n          handler_test.go             # Component tests (httptest + mock service)\n      \n          # --- Domain (Business Logic) ---\n          logic.go                    # Core business logic methods\n          logic_test.go               # Unit tests (Pure functions + mock storage)\n          models.go                   # Domain structs (Task, NewTaskRequest)\n          errors.go                   # Feature-specific errors\n      \n          # --- Storage (Data Access) ---\n          storage.go                  # Storage Interface definition\n          storage_pg.go               # Postgres implementation\n          postgres_integration_test.go # Integration tests (Real DB/Testcontainers)\n          storage_mock.go             # Mock implementation\n          ...   \n        order/                        # Order management\n          handler.go\n          logic.go\n          storage.go  \n        ...\n    frontend/                         # Frontend application source code\n      src/\n        assets/                       # Fonts, Images\n        features/                     # Business features organized as vertical slices. Each feature is SELF-CONTAINED.\n          task/                       # Task management\n            components/               # Task Feature-specific components go HERE, DON'T Put feature components in top-level folders\n              TaskForm.vue\n              TaskListItem.vue\n              TaskFilters.vue\n              TaskInput.vue\n              TaskInput.spec.ts       # Component unit tests\n            store/\n              task.store.ts           # Pinia store\n              task.store.spec.ts      # Store unit tests\n            api/\n              task.api.ts             # interface TaskAPI\n              task.api.backend.ts     # Production implementation\n              task.api.mock.ts        # Test implementation\n            services/\n              task.service.ts         # Business logic\n              task.service.spec.ts    # Logic unit tests\n            types/                    # TS Interfaces for tasks (e.g. CreateTaskDTO interfaces)\n            composables/              # Task Feature-specific hooks (e.g. useTaskFilters.ts)\n            index.ts                  # Public exports. Export ONLY what's needed by `views/`\n          order/\n        composables/                  # Global reactive logic (useAuth, useTheme)\n        components/                   # Shared Component (Buttons, Inputs) - Dumb UI, No Domain Logic. DON'T Put feature components HERE\n          ui/                         # UI Components (Atoms & Molecules) Pure, reusable UI primitives. NO domain logic, NO feature knowledge.\n            BaseButton.vue\n            BaseButton.spec.ts        # Unit tests for button states\n            types.ts                  # Shared UI types/interfaces\n            index.ts                  # Barrel export for easy imports\n          layout/                     # Layout Components (Organisms) Composite UI structures that combine multiple UI components. Still reusable, but more complex.\n            AppHeader.vue             # Application header with nav, logo, user menu\n            AppSidebar.vue            # Sidebar navigation structure\n            ErrorBoundary.vue         # Error display wrapper\n            EmptyState.vue            # Empty list placeholder\n        layouts/                      # App shells (Sidebar, Navbar wrappers)\n          MainLayout.vue              # Contains Navbar, Sidebar, Footer\n          AuthLayout.vue              # Minimal layout for Login/Register\n        views/                        # Route entry points (The \"Glue\")\n          HomeView.vue                # Imports from features/analytics\n          TaskView.vue                # Imports from features/task\n        utils/                        # Pure, stateless helper functions. No domain knowledge, no Vue reactivity, (e.g. date-fns wrappers, math).\n        router/                       # Route definitions\n        plugins/                      # Library configs (Axios, I18n)\n        App.vue                       # Root component (hosts <router-view>)\n        main.ts                       # Entry point (bootstraps plugins & mounts app)     \n      ...\n  e2e/                                # Shared E2E suite\n    api/\n      task-api.e2e.test.ts            # Backend-only E2E\n    ui/\n      task-flow.e2e.test.ts           # Full-stack E2E\n```\n> This Feature/Domain/UI/API structure is framework-agnostic. It applies equally to React, Vue, Svelte, and Mobile (React Native/Flutter). 'UI' always refers to the framework's native component format (.tsx, .vue, .svelte, .dart).",
    ".agent/rules/resources-and-memory-management-principles.md": "---\ntrigger: model_decision\ndescription: When working with resources requiring cleanup (files, database connections, network sockets, locks) or implementing resource pools\n---\n\n## Resource and Memory Management Principles\n\n### Universal Resource Management Rules\n\n**1. Always Clean Up Resources**\n\n**Resources requiring cleanup:**\n\n- Files, network connections, database connections  \n- Locks, semaphores, mutexes  \n- Memory allocations (in manual-memory languages)  \n- OS handles, GPU resources\n\n**Clean up in ALL paths:**\n\n- Success path: Normal completion  \n- Error path: Exception thrown, error returned  \n- Early return path: Guard clauses, validation failures\n\n**Use language-appropriate patterns:**\n\n- Go: defer statements  \n- Rust: Drop trait (RAII)  \n- Python: context managers (with statement)  \n- TypeScript: try/finally  \n- Java: try-with-resources\n\n**2. Timeout All I/O Operations**\n\n**Why timeout:**\n\n- Network requests can hang indefinitely  \n- Prevents resource exhaustion (connections, threads)  \n- Provides predictable failure behavior\n\n**Timeout recommendations:**\n\n- Network requests: 30s default, shorter (5-10s) for interactive  \n- Database queries: 10s default, configure per query complexity  \n- File operations: Usually fast, but timeout on network filesystems  \n- Message queue operations: Configurable, avoid indefinite blocking\n\n**3. Pool Expensive Resources**\n\n**Resources to pool:**\n\n- Database connections: Pool size 5-20 per app instance  \n- HTTP connections: Reuse with keep-alive  \n- Thread pools: Size based on CPU count (CPU-bound) or I/O wait (I/O-bound)\n\n**Benefits:**\n\n- Reduces latency (no connection setup overhead)  \n- Limits resource consumption (cap on max connections)  \n- Improves throughput (reuse vs create new)\n\n**Connection Pool Best Practices:**\n\n- Minimum connections: 5 (ensures pool is warm)  \n- Maximum connections: 20-50 (prevents overwhelming database)  \n- Idle timeout: Close connections idle >5-10 minutes  \n- Validation: Test connections before use (avoid broken connections)  \n- Monitoring: Track utilization, wait times, timeout rates\n\n**4. Avoid Resource Leaks**\n\n**What is a leak:**\n\n- Acquire resource (open file, allocate memory, get connection)  \n- Never release it (forget to close, exception prevents cleanup)  \n- Eventually exhaust system resources (OOM, max connections, file descriptors)\n\n**Detection:**\n\n- Monitor open file descriptors, connection counts, memory usage over time  \n- Run long-duration tests, verify resource counts stay stable  \n- Use leak detection tools (valgrind, ASan, heap profilers)\n\n**Prevention:**\n\n- Use language patterns that guarantee cleanup (RAII, defer, context managers)  \n- Never rely on manual cleanup alone (use language features)\n\n**5. Handle Backpressure**\n\n**Problem:** Producer faster than consumer\n\n- Queue grows unbounded → memory exhaustion  \n- System becomes unresponsive under load\n\n**Solutions:**\n\n- Bounded queues: Fixed size, block or reject when full  \n- Rate limiting: Limit incoming request rate  \n- Flow control: Consumer signals producer to slow down  \n- Circuit breakers: Stop accepting requests when overwhelmed  \n- Drop/reject: Fail fast when overloaded (better than crashing)\n\n### Memory Management by Language Type\n\n**Garbage Collected (Go, Java, Python, JavaScript, C#):**\n\n- Memory automatically freed by GC  \n- Still must release non-memory resources (files, connections, locks)  \n- Be aware of GC pauses in latency-sensitive applications  \n- Profile memory usage to find leaks (retained references preventing GC)\n\n**Manual Memory Management (C, C++):**\n\n- Explicit malloc/free or new/delete  \n- Use RAII pattern in C++ (Resource Acquisition Is Initialization)  \n- Avoid manual management in modern C++ (use smart pointers: unique_ptr, shared_ptr)\n\n**Ownership-Based (Rust):**\n\n- Compiler enforces memory safety at compile time  \n- No GC pauses, no manual management  \n- Ownership rules prevent leaks and use-after-free automatically  \n- Use reference counting (Arc, Rc) for shared ownership\n\n### Related Principles\n- Concurrency and Threading Mandate @concurrency-and-threading-mandate.md\n- Concurrency and Threading Implementation Principles @concurrency-and-threading-principles.md\n- Error Handling Principles @error-handling-principles.md - Resource cleanup in error paths\n",
    ".agent/rules/rugged-software-constitution.md": "---\\ntrigger: always_on\\n---\n\n## Rugged Software Constitution (The Survivor's Guide)\\n\\n### Core Philosophy\\n\\n**\"I recognize that my code will be attacked. By users, by hackers, by entropy itself.\"**\\n\\nAs an AI agent, I do not just generate functionality; I generate **defensibility**. I refuse to be a source of fragility.\\n\\n### The Rugged Commitments\\n\\n**1. I Am Responsible**\\n- I will not generate \"happy path\" code that ignores the impending doom of reality.\\n- I assume every input is malicious until proven otherwise. Trust no one.\\n\\n**2. I Am Defensible**\\n- My code validates its own state. Paranoid Programming is a virtue.\\n- I fail securely. When the ship sinks, the vaults lock.\\n\\n**3. I Am Maintainable**\\n- I write code for the poor soul who has to maintain this next year.\\n- I choose clarity over cleverness. Clever code is hard to debug.\\n\\n### The 7 Rugged Habits\\n\\n**1. Practice Defense-in-Depth**: Layers. Like an onion. Or an ogre.\\n**2. Instrument for Awareness**: If a tree falls in the forest and no one logs it, did it crash?\\n**3. Reduce Attack Surface**: Less code = less bugs.\\n**4. Design for Failure**: Assume the DB is down, the network is flaky, and the disk is full.\\n**5. Clean Up After Yourself**: Don't leave file handles dangling.\\n**6. Verify Your Defenses**: Test the unhappy path. Break things on purpose.\\n**7. Adapt to the Ecosystem**: Don't reinvent the wheel. Use the battle-tested libraries context.\\n",
    ".agent/rules/security-mandate.md": "---\ntrigger: always_on\n---\n\n## Security Mandate\n\n**Security is a foundational requirement, not a feature.**\n\n### Universal Security Principles\n\n1. **Never trust user input:** All data from users, APIs, or external sources must be validated server-side\n2. **Deny by default:** Require explicit permission grants, never assume access\n3. **Fail securely:** When errors occur, fail closed (deny access) rather than open\n4. **Defense in depth:** Multiple layers of security, never rely on a single control\n\n**When implementing security-sensitive features (auth, validation, queries), see Security Principles @security-principles.md for detailed implementation guidance.**\n\n### Related Principles\n- Security Principles @security-principles.md",
    ".agent/rules/security-principles.md": "---\ntrigger: model_decision\ndescription: When implementing authentication, authorization, input validation, cryptographic operations, or handling user input and sensitive data\n---\n\n## Security Principles\n\n### OWASP Top 10 Enforcement\n\n* **Broken Access Control:** Deny by default. Validate permissions *server-side* for every request. Do not rely on UI state.  \n* **Cryptographic Failures:** Use TLS 1.2+ everywhere. Encrypt PII/Secrets at rest. Use standard algorithms (AES-256, RSA-2048, Ed25519). *Never* roll your own crypto.  \n* **Injection:** ZERO TOLERANCE for string concatenation in queries. Use Parameterized Queries (SQL) or ORM bindings. Sanitize all HTML/JS output.  \n* **SSRF Prevention:** Validate all user-provided URLs against an allowlist. Disable HTTP redirects in fetch clients. Block requests to internal IPs (metadata services, localhost).  \n* **Insecure Design:** Threat model every new feature. Fail securely (closed), not openly.  \n* **Vulnerable Components:** Pin dependency versions. Scan for CVEs in CI/CD.\n\n### Authentication & Authorization\n\n* **Passwords:** Hash with Argon2id or Bcrypt (min cost 12). Never plain text.  \n* **Tokens:**  \n  * *Access Tokens:* Short-lived (15-30 mins). HS256 or RS256.  \n  * *Refresh Tokens:* Long-lived (7-30 days). Rotate on use. Store in `HttpOnly; Secure; SameSite=Strict` cookies.  \n* **Rate Limiting:** Enforce strictly on public endpoints (Login, Register, Password Reset). Standard: 5 attempts / 15 mins.  \n* **MFA:** Required for Admin and Sensitive Data access.  \n* **RBAC:** Map permissions to Roles, not Users. Check permissions at the Route AND Resource level.\n\n### Input Validation & Sanitization\n\n* **Principle:** \"All Input is Evil until Proven Good.\"  \n* **Validation:** Validate against a strict Schema (Zod/Pydantic) at the *Controller/Port* boundary.  \n* **Allowlist:** Check for \"Good characters\" (e.g., `^[a-zA-Z0-9]+$`), do not try to filter \"Bad characters.\"  \n* **Sanitization:** Strip dangerous tags from rich text input using a proven library (e.g., DOMPurify equivalent).\n\n### Logging & Monitoring (Security Focus)\n\n* **Redaction:** SCRUB all PII, Secrets, Tokens, and Passwords from logs *before* writing.  \n* **Events:** Log all *failed* auth attempts, access denied events, and input validation failures.  \n* **Format:** JSON structured logs with `correlationId`, `user_id`, and `event_type`.  \n* **Anti-Tamper:** Logs should be write-only for the application.\n\n### Secrets Management\n\n* **Storage:** Never commit secrets to git. Use `.env` (local) or Secret Managers (Prod - e.g., Vault/GSM).\n\n### Related Principles\n- Error Handling Principles @error-handling-principles.md\n- API Design Principles @api-design-principles.md\n- Logging and Observability Mandate @logging-and-observability-mandate.md\n- Logging and Observability Principles @logging-and-observability-principles.md\n- Configuration Management Principles @configuration-management-principles.md",
    ".agent/rules/testing-strategy.md": "---\ntrigger: model_decision\ndescription: When writing tests, organizing test files, implementing test doubles, or setting up testing infrastructure\n---\n\n## Testing Strategy\n\n### Test Pyramid\n\n**Unit Tests (70% of tests):**\n\n- **What:** Test domain logic in isolation with mocked dependencies  \n- **Speed:** Fast (<100ms per test)  \n- **Scope:** Single function, class, or module  \n- **Dependencies:** All external dependencies mocked (repositories, APIs, time, random)  \n- **Coverage Goal:** >85% of domain logic\n\n**Integration Tests (20% of tests):**\n\n- **What:** Test adapters against real infrastructure  \n- **Speed:** Medium (100ms-5s per test)  \n- **Scope:** Component interaction with infrastructure (database, cache, message queue)  \n- **Dependencies:** Real infrastructure via Testcontainers  \n- **Coverage Goal:** All adapter implementations, critical integration points\n\n**End-to-End Tests (10% of tests):**\n\n- **What:** Test complete user journeys through all layers  \n- **Speed:** Slow (5s-30s per test)  \n- **Scope:** Full system from HTTP request to database and back  \n- **Dependencies:** Entire system running (or close approximation)  \n- **Coverage Goal:** Happy paths, critical business flows\n\n### Test-Driven Development (TDD)\n\n**Red-Green-Refactor Cycle:**\n\n1. **Red:** Write a failing test for next bit of functionality  \n2. **Green:** Write minimal code to make test pass  \n3. **Refactor:** Clean up code while keeping tests green  \n4. **Repeat:** Next test\n\n**Benefits:**\n\n- Tests written first ensure testable design  \n- Comprehensive test coverage (code without test doesn't exist)  \n- Faster development (catch bugs immediately, not in QA)  \n- Better design (forces thinking about interfaces before implementation)\n\n### Test Doubles Strategy\n\n**Unit Tests:** Use mocks/stubs for all driven ports\n\n- Mock repositories return pre-defined data  \n- Mock external APIs return successful responses  \n- Mock time/random for deterministic tests  \n- Control test environment completely\n\n**Integration Tests:** Use real infrastructure\n\n- Testcontainers spins up PostgreSQL, Redis, message queues  \n- Firebase emulator spins up Firebase Authentication, Cloud Firestore, Realtime Database, Cloud Storage for Firebase, Firebase Hosting, Cloud Functions, Pub/Sub, and Firebase Extensions  \n- Test actual database queries, connection handling, transactions  \n- Verify adapter implementations work with real services\n\n**Best Practice:**\n\n- Generate at least 2 implementations per driven port:  \n  1. Production adapter (PostgreSQL, GCP GCS, etc.)  \n  2. Test adapter (in-memory, fake implementation)\n\n### Test Organization\n\n**Universal Rule: Co-locate implementation tests; Separate system tests.**\n\n**1. Unit & Integration Tests (Co-located)**\n- **Rule:** Place tests **next to the file** they test.\n- **Why:** Keeps tests visible, encourages maintenance, and supports refactoring (moving a file moves its tests).\n- **Naming Convention Example:**\n  - **TS/JS:** `*.spec.ts` (Unit), `*.integration.spec.ts` (Integration)\n  - **Go:** `*_test.go` (Unit), `*_integration_test.go` (Integration)\n  - **Python:** `test_*.py` (Unit), `test_*_integration.py` (Integration)\n  - **Java:** `*Test.java` (Unit), `*IT.java` (Integration)\n  > You must strictly follow the convention for the target language. Do not mix `test` and `spec` suffixes in the same application context.\n\n**2. End-to-End Tests (Separate)**\n- **Rule:** Place in a dedicated `e2e/` folder\n  - **Single Service:** `e2e/` at project root\n  - **Monorepo:** `apps/e2e/` subdivided by test scope:\n    - `apps/e2e/api/` for full API flow E2E tests (HTTP → Database)\n    - `apps/e2e/ui/` for full-stack E2E tests (Browser → Backend → Database)\n- **Why:** E2E tests cross boundaries and don't belong to a single feature.\n- **Naming:** Follow `{feature}-{ui/api}.e2e.test.{ext}` (Universal - configure test runner to match this pattern `**/*.e2e.test.*`)\n  - Example: \n    - `user-registration-api.e2e.test.ts`       # Full API flow: HTTP → DB\n    - `user-registration-ui.e2e.test.ts`        # Full-stack: Browser → Backend → DB\n\n**Using Playwright MCP for UI E2E Tests:**\n\nWhen running E2E tests interactively (during development or verification), use Playwright MCP:\n\n```\n# Navigate to the page\nmcp_playwright_browser_navigate(url=\"http://localhost:5173/login\")\n\n# Capture accessible state (better than screenshot for assertions)\nmcp_playwright_browser_snapshot()\n\n# Interact with elements by ref from snapshot\nmcp_playwright_browser_type(ref=\"<ref>\", text=\"test@example.com\")\nmcp_playwright_browser_click(ref=\"<ref>\")\n\n# Wait for results\nmcp_playwright_browser_wait_for(text=\"Welcome\")\n\n# Take screenshot for walkthrough documentation\nmcp_playwright_browser_take_screenshot(filename=\"login-success.png\")\n```\n\n**E2E Test Requirements:**\n- Take screenshot at each major step\n- Save screenshots to walkthrough as proof of functionality\n- Test happy path AND at least one error path\n- Clean up test data after test (or use unique identifiers)\n\n**Key Principles:**\n- **Unit/Integration tests**: Co-located with implementation\n- **E2E tests**: Separate directory (crosses boundaries)\n- **Test doubles**: Co-located with interface (mock_store.go, taskAPI.mock.ts)\n- **Pattern consistency**: All features follow same structure  \n\n### Test Quality Standards\n\n**AAA Pattern (Arrange-Act-Assert):**\n```\n// Arrange: Set up test data and mocks\nconst user = { id: '123', email: 'test@example.com' };\nconst mockRepo = createMockRepository();\n\n// Act: Execute the code under test\nconst result = await userService.createUser(user);\n\n// Assert: Verify expected outcome\nexpect(result.id).toBe('123');\nexpect(mockRepo.save).toHaveBeenCalledWith(user);\n```\n**Test Naming:**\n\n- Descriptive: `should [expected behavior] when [condition]`  \n- Examples:  \n  - `should return 404 when user not found`  \n  - `should hash password before saving to database`  \n  - `should reject email with invalid format`\n\n**Coverage Requirements:**\n\n- Unit tests: >85% code coverage  \n- Integration tests: All adapter implementations  \n- E2E tests: Critical user journeys\n\n### Related Principles\n- Architectural Patterns - Testability-First Design @architectural-pattern.md\n- Error Handling Principles @error-handling-principles.md\n- Project Structure @project-structure.md",
    ".agent/workflows/1-research.md": "---\ndescription: Research phase - understand context and gather knowledge\n---\n\n# Phase 1: Research\n\n## Purpose\nUnderstand the request context AND gather accurate, up-to-date knowledge before writing any code.\n\n## Steps\n\n### 1. Analyze Request\nParse the user's request and identify:\n- What are they asking for?\n- What is the scope?\n\n### 2. Review Current Implementation\nCheck the repository to understand:\n- Current technical architecture\n- Existing implementation patterns\n- Dependencies and configurations\n\n### 3. Build Mental Model\nInventory:\n- Business requirements\n- Technical constraints\n- Integration points with existing code\n\n### 4. Define Scope\nUse `task_boundary` to set mode to **PLANNING**\n\nCreate a plan with bite-sized atomic tasks in `task.md`:\n- `[ ]` = Not started\n- Use indented lists for sub-items\n\n### 5. Identify Research Topics\nList all technologies, libraries, and patterns involved in this task.\n\nExample:\n```\nTopics for \"Task CRUD API\":\n- Go http.ServeMux routing patterns\n- SQLC query generation\n- UUID handling in PostgreSQL\n- JWT authentication middleware\n```\n\n### 6. Search Qurio\nRun searches for EACH topic:\n\n[comment]: # (2-5 keywords only!)\n\n```\nqurio_search(query=\"Go ServeMux routing\")\nqurio_search(query=\"SQLC CRUD queries\")\nqurio_search(query=\"Pinia store setup\")\n\n# More complex query\nqurio_search(query=\"<tech-keywords>\", alpha=0.5)\nqurio_search(query=\"<tech-keywords>\", alpha=0.5, limit=10, source_id=\"<source_id>\")\n\n# Read full page\nqurio_read_page(url=\"https://go.dev/doc/go1.25\")\n```\n\n### 7. Document Findings\nCreate `.agent/research_logs/{feature_name}.md` with:\n- Key patterns discovered\n- Code examples from documentation\n- API signatures and options\n- Gotchas or edge cases found\n\n#### Research Log Naming\nEach feature should have its own research log:\n```\n.agent/research_logs/\n├── epic1_auth.md           # Epic 1: Authentication\n├── epic2_task.md           # Epic 2: Task CRUD\n├── epic3_lists.md          # Epic 3: Lists\n└── {feature_name}.md       # Pattern: one log per feature\n```\n\n### 8. Fallback to Web Search\nIf Qurio yields no results, use web search.\n\n### 9. State Training Data Usage\nIf relying on training data, explicitly state:\n> \"I am relying on my training data for this solution as external verification was unavailable.\"\n\n## If This Phase Fails\nIf Qurio and web search yield no results:\n1. Document what was searched\n2. State: \"Relying on training data\"\n3. Proceed with caution\n4. Flag for human review if critical\n\n## Completion Criteria\n- [ ] Request analyzed and scope defined\n- [ ] `task.md` created with atomic tasks\n- [ ] Research log created at `.agent/research_logs/{feature_name}.md`\n- [ ] All major technologies researched\n- [ ] Code examples documented\n\n## Next Phase\nProceed to **Phase 2: Implement** (`/2-implement`)",
    ".agent/workflows/2-implement.md": "---\ndescription: Implement phase - TDD cycle for writing code\n---\n\n# Phase 2: Implement\n\n## Purpose\nWrite production code following Test-Driven Development (TDD).\n\n## Prerequisites\n- Phase 1 (Research) completed\n- Research log exists at `.agent/research_logs/{feature_name}.md`\n- Mark task as `[/]` in task.md\n\n## Steps\n\n**Set Mode:** Use `task_boundary` to set mode to **EXECUTION**.\n\n### 1. Create Test File\nCo-locate with implementation:\n- Go: `*_test.go`\n- TypeScript: `*.spec.ts`\n\n### 2. Write Failing Test (Red)\n```go\nfunc TestCreateTask_Success(t *testing.T) {\n    // Arrange\n    mockStore := NewMockStorage()\n    service := NewService(mockStore, logger)\n    \n    // Act\n    task, err := service.Create(ctx, userID, req)\n    \n    // Assert\n    require.NoError(t, err)\n    assert.Equal(t, \"Test Task\", task.Title)\n}\n```\n\nRun test to confirm it fails:\n```bash\n# Go\ngo test -v ./internal/features/{feature}/...\n\n# Frontend\npnpm run test -- --watch\n```\n\n### 3. Write Minimal Code (Green)\nWrite ONLY enough code to make the test pass.\n\nRun test to confirm it passes:\n```bash\ngo test -v ./internal/features/{feature}/...\n```\n\n### 4. Refactor (Blue)\nImprove the code while keeping tests green:\n- Improve names and structure\n- Remove duplication\n- **Follow predefined agent rules** (read applicable `.agent/rules/*.md`)\n- **Handle errors** per Error Handling Principles\n- **Add logging** per Logging and Observability Mandate\n- Ensure tests still pass\n\n### 5. Repeat\nContinue Red-Green-Refactor for each behavior.\n\n## Unit Test Requirements\n- Mock all dependencies (interfaces)\n- Test happy path, error paths AND edge cases\n- Target >85% coverage on domain logic\n\n## Development Commands\n```bash\n# Run specific test\ngo test -v -run TestCreateTask ./internal/features/task/...\n\n# Run with coverage\ngo test -cover ./internal/features/task/...\n\n# Frontend tests\npnpm run test\npnpm run test -- --coverage\n```\n\n## Completion Criteria\n- [ ] Unit tests written and passing\n- [ ] Implementation complete\n- [ ] Error handling follows principles\n- [ ] Logging added to operations\n- [ ] Code follows project patterns\n\n## Next Phase\nProceed to **Phase 3: Integrate** (`/3-integrate`)",
    ".agent/workflows/3-integrate.md": "---\ndescription: Integrate phase - test adapters with real infrastructure\n---\n\n# Phase 3: Integrate\n\n## Purpose\nTest adapter implementations (database, external APIs) with real infrastructure using Testcontainers.\n\n## Prerequisites\n- Phase 2 (Implement) completed\n- Unit tests passing\n\n## When Required\n- Any code that touches database (storage implementations)\n- Any code that calls external APIs\n- Any code that uses message queues, caches, etc.\n\n## If This Phase Fails\nIf integration tests fail:\n1. Check container logs for errors\n2. Verify schema matches expectations\n3. Fix adapter implementation\n4. Re-run tests before proceeding\n\n## Steps\n\n### 1. Setup Testcontainers\n\n**Go Example:**\n```go\nfunc TestPostgresStorage_Integration(t *testing.T) {\n    if testing.Short() {\n        t.Skip(\"skipping integration test\")\n    }\n    \n    ctx := context.Background()\n    \n    // Start PostgreSQL container\n    postgres, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{\n        ContainerRequest: testcontainers.ContainerRequest{\n            Image:        \"postgres:16-alpine\",\n            ExposedPorts: []string{\"5432/tcp\"},\n            Env: map[string]string{\n                \"POSTGRES_USER\":     \"test\",\n                \"POSTGRES_PASSWORD\": \"test\",\n                \"POSTGRES_DB\":       \"test\",\n            },\n            WaitingFor: wait.ForListeningPort(\"5432/tcp\"),\n        },\n        Started: true,\n    })\n    require.NoError(t, err)\n    defer postgres.Terminate(ctx)\n    \n    // Get connection string and run tests\n}\n```\n\n### 2. Write Integration Tests\nTest file naming: `*_integration_test.go` or `*.integration.spec.ts`\n\n```go\nfunc TestPostgresStorage_CreateTask(t *testing.T) {\n    // Uses real PostgreSQL from Testcontainers\n    storage := NewPostgresStorage(pool)\n    \n    task, err := storage.Create(ctx, userID, req)\n    \n    require.NoError(t, err)\n    assert.NotEqual(t, uuid.Nil, task.ID)\n}\n```\n\n### 3. Run Integration Tests\n```bash\n# Go - run all tests including integration\ngo test -v ./...\n```\n\n### 4. Manual Check (Optional)\n- If UI involved, launch a browser to verify the basic flow.\n- If API involved, use `curl` or `client` to hit the endpoint.\n\n## Completion Criteria\n- [ ] Integration tests written for all adapters\n- [ ] Tests pass with real infrastructure (Testcontainers)\n- [ ] Database queries verified against real PostgreSQL\n\n## Next Phase\nProceed to **Phase 4: Verify** (`/4-verify`)",
    ".agent/workflows/4-verify.md": "---\ndescription: Verify phase - run full validation suite\n---\n\n# Phase 4: Verify\n\n## Purpose\nRun all linters, static analysis, and tests to ensure code quality.\n\n## Prerequisites\n- Phase 3 (Integrate) completed (or skipped if no adapters)\n- All tests passing\n\n## If This Phase Fails\nIf lint/test/build fails:\n1. **Do not proceed** to Ship\n2. Fix the issue (go back to Phase 2 or 3 as needed)\n3. Re-run full verification\n4. Only proceed when ALL checks pass\n\n## Steps\n\n**Set Mode:** Use `task_boundary` to set mode to **VERIFICATION**.\n\n### 1. Backend Validation\nRun the FULL validation suite:\n\n```bash\n# // turbo\ncd apps/backend && gofumpt -l -e -w . && go vet ./... && staticcheck ./... && gosec -quiet ./... && go test -race ./...\n```\n\n### 2. Frontend Validation\n```bash\n# // turbo\ncd apps/frontend && pnpm run lint --fix && npx vue-tsc --noEmit && pnpm run test\n```\n\n### 3. Build Check\n```bash\n# Backend\ncd apps/backend && go build ./...\n\n# Frontend\ncd apps/frontend && pnpm run build\n```\n\n### 4. Check Coverage\nReport actual coverage in task summary.\n\n**Go:**\n```bash\ngo test -cover ./internal/features/...\n```\n\n**Frontend:**\n```bash\npnpm run test -- --coverage\n```\n\n## Completion Criteria\n- [ ] All lint checks pass\n- [ ] All tests pass\n- [ ] Build succeeds\n- [ ] Coverage reported (target >85% on domain logic)\n\n## On Success\nMark task as `[x]` in task.md (verification passed = task complete).\n\n## Next Phase\nProceed to **Phase 5: Ship** (`/5-commit`)",
    ".agent/workflows/5-commit.md": "---\ndescription: Git commit with conventional format\n---\n\n# Ship: Commit\n\n## Purpose\nCommit completed work with proper conventional commit format.\n\n## Prerequisites\n- All verification checks pass\n- Code is ready for review/merge\n\n## Steps\n\n### 1. Review Changes\n```bash\ngit status\ngit diff --staged\n```\n\n### 2. Stage Changes\n```bash\n# Stage all changes\ngit add .\n\n# Or stage selectively\ngit add apps/backend/internal/features/task/\n```\n\n### 3. Commit with Conventional Format\n\n**Format:**\n```\n<type>(<scope>): <description>\n\n[optional body]\n\n[optional footer]\n```\n\n**Types:**\n- `feat`: New feature\n- `fix`: Bug fix\n- `docs`: Documentation only\n- `style`: Formatting, semicolons, etc.\n- `refactor`: Code change (no new feature/fix)\n- `test`: Adding tests\n- `chore`: Maintenance\n\n**Examples:**\n```bash\ngit commit -m \"feat(task): add CRUD API endpoints\"\ngit commit -m \"feat(auth): implement JWT authentication\"\ngit commit -m \"fix(task): correct status validation\"\ngit commit -m \"test(task): add unit tests for service layer\"\n```\n\n### 4. Update task.md\nMark completed items as `[x]` in the task checklist.\n\n## Commit Scope Guidelines\n\n| Feature Area | Scope |\n|--------------|-------|\n| Task management | `task` |\n| User/Auth | `auth` |\n| Lists | `list` |\n| API layer | `api` |\n| Database | `db` |\n| Frontend | `ui` |\n\n## Completion Criteria\n- [ ] Changes committed with proper format\n- [ ] task.md updated to reflect completion\n",
    ".agent/workflows/e2e-test.md": "---\ndescription: End-to-end testing with Playwright MCP\n---\n\n# E2E Testing Workflow\n\n## Purpose\nValidate complete user journeys through the full system using Playwright MCP.\n\n## When to Use\n- After completing an epic/milestone\n- Before release/deploy\n- When adding critical user flows\n\n## Prerequisites\n- Services running (docker compose up or local dev)\n- Feature implementation complete\n- Unit and integration tests passing\n\n## Steps\n\n### 1. Start Services\nEnsure the full stack is running:\n```bash\ndocker compose up -d\n# Wait for health checks\ndocker compose ps\n```\n\nOr local development:\n```bash\n# Terminal 1: Backend\ncd apps/backend && go run cmd/api/main.go\n\n# Terminal 2: Frontend  \ncd apps/frontend && pnpm run dev\n```\n\n### 2. Create E2E Test Plan\nDocument test cases in `e2e/{feature}-{ui|api}.e2e.test.ts`:\n- Happy path flows\n- Error handling\n- Edge cases\n\n### 3. Execute with Playwright MCP\n\n**Navigate to page:**\n```\nmcp_playwright_browser_navigate(url=\"http://localhost:5173/login\")\n```\n\n**Capture page state:**\n```\nmcp_playwright_browser_snapshot()\n```\n\n**Interact with elements (use refs from snapshot):**\n```\nmcp_playwright_browser_type(ref=\"<ref>\", text=\"test@example.com\")\nmcp_playwright_browser_click(ref=\"<ref>\")\n```\n\n**Wait for results:**\n```\nmcp_playwright_browser_wait_for(text=\"Welcome\")\n```\n\n**Take screenshot for documentation:**\n```\nmcp_playwright_browser_take_screenshot(filename=\"login-success.png\")\n```\n\n### 4. Document Results\n- Save screenshots to walkthrough\n- Note any failures or issues\n- Update test files if needed\n\n## E2E Test Structure\n\n```\ne2e/\n├── api/\n│   └── task-crud-api.e2e.test.ts    # API-only E2E\n└── ui/\n    ├── auth-flow-ui.e2e.test.ts     # Browser E2E\n    └── task-flow-ui.e2e.test.ts\n```\n\n## Example: Auth Flow E2E\n\n```typescript\n// e2e/ui/auth-flow-ui.e2e.test.ts\ndescribe('Authentication Flow', () => {\n  it('should register a new user', async () => {\n    // Navigate to register\n    // Fill form\n    // Submit\n    // Verify redirect to dashboard\n  });\n\n  it('should login existing user', async () => {\n    // Navigate to login\n    // Fill credentials\n    // Submit\n    // Verify dashboard loads\n  });\n\n  it('should show error for invalid credentials', async () => {\n    // Navigate to login\n    // Fill wrong password\n    // Submit\n    // Verify error message\n  });\n});\n```\n\n## Completion Criteria\n- [ ] All critical user flows tested\n- [ ] Screenshots captured for walkthrough\n- [ ] No blocking issues found\n",
    ".agent/workflows/orchestrator.md": "---\ndescription: Build feature workflow orchestrator - chains all phases\n---\n\n# Build Feature Workflow\n\n**CRITICAL INSTRUCTION**\n\nYOU ARE FORBIDDEN FROM SKIPPING PHASES.\nYou must treat this file as a State Machine. You cannot transition to state $N+1$ until state $N$ is completely verified.\n\n## Role\nYou are a Senior Principal Engineer with a mandate for strict protocol adherence.\n\nYour responsibility is to deliver clean, testable, and idiomatic code while rigidly enforcing the End-to-End Workflow Phases. You must reject any attempt to skip phases—such as writing code without research or completing task/shipping without verification.\n\nCrucially, you MUST strictly adhere to the comprehensive rule sets defined in .agent/rules/ (e.g., error handling, logging, security, concurrency). These rules are non-negotiable constraints that supersede general training data.\n\n## Pre-Implementation Checklist\nBefore starting any work, you MUST:\n1. Scan `.agent/rules/` directory\n2. Identify applicable rules for this task\n3. **READ** selected rule files (they are non-negotiable constraints)\n\n## Workflow Phases\n\nExecute phases **sequentially**. Do not skip phases for velocity.\nNever deferred quality gates to a later \"hardening\" phase, defensive rigour early in the cycle trumps.\n\n```\ngraph LR\n    P1[Research] -->|Log Created| P2[Implement]\n    P2 -->|Unit Tests Pass| P3[Integrate]\n    P3 -->|Integration Tests Pass| P4[Verify]\n    P4 -->|All Linters Pass| P5[Ship]\n```\n\n### Phase 1: Research\n**File:** `1-research.md`\n- Analyze request, understand context\n- Define scope in `task.md`\n- Search Qurio for each technology\n- Document findings in `.agent/research_logs/{feature}.md`\n\n### Phase 2: Implement\n**File:** `2-implement.md`\n- TDD cycle: Red → Green → Refactor\n- Unit tests with mocked dependencies\n\n### Phase 3: Integrate\n**File:** `3-integrate.md`\n- Integration tests with Testcontainers\n- Test adapters against real infrastructure\n\n### Phase 4: Verify\n**File:** `4-verify.md`\n- Full lint/test/build validation\n- Report coverage\n\n### Phase 5: Ship\n**File:** `5-commit.md`\n- Git commit with conventional format\n- Update task.md\n\n---\n\n## Phase Management\n\n### Task.md Updates\nUse this pattern throughout phases:\n- `[ ]` = Not started\n- `[/]` = In progress (mark when **starting** a task)\n- `[x]` = Complete (mark **only after Verify phase passes**)\n\n**Rule:** Never mark `[x]` until Phase 4 (Verify) passes for that task.\n\n### Phase Transitions\nBefore moving to the next phase, **STOP and verify**:\n- [ ] Current phase completion criteria met\n- [ ] Outputs created (research log, tests, etc.)\n- [ ] No blocking errors\n\n### Error Handling\nIf a phase fails:\n1. **Document the failure** in task summary\n2. **Do not proceed** to next phase\n3. **Fix the issue** within current phase\n4. **Re-run** phase completion criteria\n5. Then proceed\n\n### Resuming Work\nTo resume from a specific phase:\n1. Read `task.md` to find current state (`[/]` items)\n2. Read the relevant phase file\n3. Continue from where you left off\n4. No need to re-run completed phases\n\n---\n\n## Quick Reference\n\n| Phase | Output | Blocking |\n|-------|--------|----------|\n| Research | `task.md` + `.agent/research_logs/*.md` | Yes |\n| Implement | Unit tests + code | Yes |\n| Integrate | Integration tests | Yes (for adapters) |\n| Verify | All checks pass | Yes |\n| Ship | Git commit | Yes |",
    ".agent/skills/debugging-protocol/SKILL.md": "---\nname: debugging-protocol\ndescription: Comprehensive protocol for validating root causes of software issues. Use when you need to systematically debug a complex bug, flaky test, or unknown system behavior by forming hypotheses and validating them with specific tasks.\n---\n\n# Debugging Protocol\n\n## Overview\n\nThis skill provides a rigorous framework for debugging complex software issues. It moves beyond ad-hoc troubleshooting to a structured process of hypothesis generation and validation.\n\nUse this skill to:\n1.  Formalize a debugging session.\n2.  Systematically eliminate potential root causes.\n3.  Document findings for future reference or team communication.\n\n## Protocol Workflow\n\nTo run a structured debugging session, follow these steps:\n\n### 1. Initialize the Session\nCreate a new debugging document using the provided template. This serves as the \"source of truth\" for the investigation.\n\nTemplate location: `assets/debugging-session-template.md`\n\n### 2. Define the Problem\nClearly articulate the **System Context** and **Problem Statement**.\n*   **Symptom**: What is the observable behavior? How does it differ from expected behavior?\n*   **Scope**: Which components are involved?\n\n### 3. Formulate Hypotheses\nList distinct, testable hypotheses.\n*   Avoid vague guesses.\n*   Differentiate between layers (e.g., \"Frontend Hypothesis\" vs \"Backend Hypothesis\").\n*   Example: \"Race condition in UI state update\" vs \"Database schema misconfiguration\".\n\n### 4. Design Validation Tasks\nFor each hypothesis, design a specific validation task.\n*   **Objective**: What are you trying to prove or disprove?\n*   **Steps**: Precise, reproducible actions.\n*   **Code Pattern**: Provide the exact code or command to run (e.g., a specific SQL query, a Python script using the client library, a `curl` command).\n*   **Success Criteria**: Explicitly state what output confirms the hypothesis.\n\n### 5. Execute and Document\nRun the tasks in order. For each task, record:\n*   **Status**: ✅ VALIDATED, ❌ FAILED, or ⚠️ INCONCLUSIVE.\n*   **Findings**: Key observations and raw evidence (logs, screenshots).\n*   **Conclusion**: Does this support or refute the hypothesis?\n\n### 6. Determine Root Cause\nSynthesize the findings into a **Root Cause Analysis**.\n*   Identify the Primary Root Cause.\n*   Assign a Confidence Level.\n*   Propose specific fixes.\n\n## Best Practices\n\n*   **Be Specific**: Don't just say \"check the logs.\" Say \"grep for 'Error 500' in `/var/log/nginx/access.log`\".\n*   **Isolate Variables**: Change one thing at a time.\n*   **Validate Assumptions**: Verify configuration and versions first (e.g., \"Task 1: Validate Current Schema\").\n*   **Preserve Evidence**: Keep the specific trace IDs, log timestamps, or reproduction scripts.",
    ".agent/skills/frontend-design/SKILL.md": "---\nname: frontend-design\ndescription: Generates distinctive, production-grade frontend interfaces and artifacts (React, Vue, HTML/CSS). Prioritizes bold aesthetics, unique typography, and motion to avoid generic designs. Use when building websites, landing pages, dashboards, posters, or when the user requests to style, beautify, or create visually striking UI.\n---\n\nThis skill guides creation of distinctive, production-grade frontend interfaces that avoid generic \"AI slop\" aesthetics. Implement real working code with exceptional attention to aesthetic details and creative choices.\n\nThe user provides frontend requirements: a component, page, application, or interface to build. They may include context about the purpose, audience, or technical constraints.\n\n## Design Thinking\n\nBefore coding, understand the context and commit to a BOLD aesthetic direction:\n- **Purpose**: What problem does this interface solve? Who uses it?\n- **Tone**: Pick an extreme: brutally minimal, maximalist chaos, retro-futuristic, organic/natural, luxury/refined, playful/toy-like, editorial/magazine, brutalist/raw, art deco/geometric, soft/pastel, industrial/utilitarian, etc. There are so many flavors to choose from. Use these for inspiration but design one that is true to the aesthetic direction.\n- **Constraints**: Technical requirements (framework, performance, accessibility).\n- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?\n\n**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.\n\nThen implement working code (HTML/CSS/JS, React, Vue, etc.) that is:\n- Production-grade and functional\n- Visually striking and memorable\n- Cohesive with a clear aesthetic point-of-view\n- Meticulously refined in every detail\n\n## Frontend Aesthetics Guidelines\n\nFocus on:\n- **Typography**: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics; unexpected, characterful font choices. Pair a distinctive display font with a refined body font.\n- **Color & Theme**: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed palettes.\n- **Motion**: Use animations for effects and micro-interactions. Prioritize CSS-only solutions for HTML. Use Motion library for React when available. Focus on high-impact moments: one well-orchestrated page load with staggered reveals (animation-delay) creates more delight than scattered micro-interactions. Use scroll-triggering and hover states that surprise.\n- **Spatial Composition**: Unexpected layouts. Asymmetry. Overlap. Diagonal flow. Grid-breaking elements. Generous negative space OR controlled density.\n- **Backgrounds & Visual Details**: Create atmosphere and depth rather than defaulting to solid colors. Add contextual effects and textures that match the overall aesthetic. Apply creative forms like gradient meshes, noise textures, geometric patterns, layered transparencies, dramatic shadows, decorative borders, custom cursors, and grain overlays.\n\nNEVER use generic AI-generated aesthetics like overused font families (Inter, Roboto, Arial, system fonts), cliched color schemes (particularly purple gradients on white backgrounds), predictable layouts and component patterns, and cookie-cutter design that lacks context-specific character.\n\nInterpret creatively and make unexpected choices that feel genuinely designed for the context. No design should be the same. Vary between light and dark themes, different fonts, different aesthetics. NEVER converge on common choices (Space Grotesk, for example) across generations.\n\n**IMPORTANT**: Match implementation complexity to the aesthetic vision. Maximalist designs need elaborate code with extensive animations and effects. Minimalist or refined designs need restraint, precision, and careful attention to spacing, typography, and subtle details. Elegance comes from executing the vision well.\n\nRemember: You are capable of extraordinary creative work. Don't hold back, show what can truly be created when thinking outside the box and committing fully to a distinctive vision.\n",
    ".agent/skills/sequential-thinking/SKILL.md": "---\nname: sequential-thinking\ndescription: Performs dynamic, reflective problem-solving through iterative thought chains. Use for complex planning requiring revision, branching, backtracking, or hypothesis verification. Ideal for multi-step analysis where context maintenance is required or the full scope isn't initially clear.\n---\n\n# Sequential Thinking\n\nA structured approach to complex problem-solving that breaks down challenges into iterative thought steps with built-in flexibility for revision and course correction.\n\n## When to Use This Skill\n\n- Breaking down complex problems into manageable steps\n- Planning and design requiring iterative refinement\n- Analysis that might need course correction mid-stream\n- Problems where the full scope emerges during analysis\n- Multi-step solutions requiring context across steps\n- Filtering out irrelevant information\n- Hypothesis generation and verification workflows\n\n## Core Methodology\n\nSequential thinking follows a dynamic process:\n\n1. **Initial estimation**: Start with an estimate of thoughts needed, but remain flexible\n2. **Iterative analysis**: Work through thoughts sequentially while building context\n3. **Revision capability**: Question or revise previous thoughts as understanding deepens\n4. **Branch exploration**: Explore alternative approaches when needed\n5. **Hypothesis cycle**: Generate hypotheses, verify against thought chain, repeat\n6. **Convergence**: Continue until reaching a satisfactory solution\n\n## Instructions\n\n### Thought Structure\n\nEach thought in the sequence should include:\n\n- **thought**: Current thinking step content\n- **thoughtNumber**: Position in sequence (1, 2, 3, ...)\n- **totalThoughts**: Current estimate of total thoughts needed (adjustable)\n- **nextThoughtNeeded**: Whether another thought step is required\n\nOptional revision/branching metadata:\n- **isRevision**: Boolean indicating if reconsidering previous thinking\n- **revisesThought**: Which thought number is being revised\n- **branchFromThought**: Branching point thought number\n- **branchId**: Identifier for current branch\n- **needsMoreThoughts**: Flag when reaching end but requiring more analysis\n\n### Process Guidelines\n\n**Starting out:**\n- Estimate initial thoughts needed based on problem complexity\n- Begin with thought 1, establishing context and approach\n- Set totalThoughts conservatively; you can adjust later\n\n**During analysis:**\n- Build on previous thoughts while maintaining context\n- Filter out irrelevant information at each step\n- Express uncertainty when present\n- Don't hesitate to revise if you spot errors or better approaches\n- Adjust totalThoughts up/down as the problem's scope becomes clearer\n\n**Revision pattern:**\nWhen reconsidering previous thinking:\n```json\n{\n  \"thought\": \"On reflection, thought 3's assumption about X was incorrect because Y...\",\n  \"thoughtNumber\": 6,\n  \"totalThoughts\": 10,\n  \"isRevision\": True,\n  \"revisesThought\": 3,\n  \"nextThoughtNeeded\": True\n}\n```\n\n**Hypothesis cycle:**\n1. Generate hypothesis based on current understanding\n2. Verify against previous thought chain\n3. If verification fails, revise or branch\n4. Repeat until hypothesis is validated\n\n**Completion:**\n- Only set `nextThoughtNeeded: False` when truly satisfied with the solution\n- Provide a single, clear final answer\n- Ensure the answer directly addresses the original problem\n\n### Working with Context\n\n**Maintain continuity:**\n- Reference specific previous thoughts by number\n- Build logical connections between thoughts\n- Track which thoughts are still valid vs. revised\n\n**Filter information:**\n- Ignore details irrelevant to current thought step\n- Focus on information that advances understanding\n- Re-evaluate relevance as context evolves\n\n**Manage complexity:**\n- If a thought becomes too complex, break it into multiple thoughts\n- Increase totalThoughts estimate accordingly\n- Keep each individual thought focused\n\n### Output Format\n\nPresent your sequential thinking in a structured format:\n```\nThought [N/Total]: [Current thought content]\n[If revision: \"This revises thought X because...\"]\n[If branching: \"Branching from thought X to explore...\"]\n\n[Continue with next thought when nextThoughtNeeded is True]\n\nFinal output after all thoughts complete:\nSolution: [Clear, direct answer to the original problem]\n\n```\n\n## Examples\n\nFor concrete examples of sequential thinking in action, see `resources/examples.md`.\n\n## Key Principles\n\n- **Flexibility over rigidity**: Adjust your approach as understanding deepens\n- **Revision is strength**: Correcting course shows good reasoning\n- **Hypothesis-driven**: Generate and test hypotheses iteratively\n- **Context-aware**: Maintain awareness of previous thoughts while progressing\n- **Clarity at completion**: Deliver a single, clear final answer\n"
};


/***/ }),
/* 7 */
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {


Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.FileHandler = void 0;
const vscode = __webpack_require__(1);
class FileHandler {
    /**
     * Writes multiple files to the workspace.
     * @param root The root URI of the workspace.
     * @param files A map of relative paths to content.
     */
    async writeFiles(root, files) {
        for (const [relativePath, content] of files) {
            const targetUri = vscode.Uri.joinPath(root, relativePath);
            await this.writeSingleFile(targetUri, content);
        }
    }
    async writeSingleFile(uri, content) {
        // Ensure directory exists
        const parentDir = vscode.Uri.joinPath(uri, '..');
        await vscode.workspace.fs.createDirectory(parentDir);
        // Write file
        const encoder = new TextEncoder();
        const data = encoder.encode(content);
        await vscode.workspace.fs.writeFile(uri, data);
    }
}
exports.FileHandler = FileHandler;


/***/ })
/******/ 	]);
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId](module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
var __webpack_exports__ = {};
// This entry needs to be wrapped in an IIFE because it needs to be isolated against other modules in the chunk.
(() => {
var exports = __webpack_exports__;

Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.activate = activate;
exports.deactivate = deactivate;
const vscode = __webpack_require__(1);
const watcher_1 = __webpack_require__(2);
const ui_controller_1 = __webpack_require__(4);
const github_client_1 = __webpack_require__(5);
const file_handler_1 = __webpack_require__(7);
function activate(context) {
    console.log('Congratulations, your extension "agent-init" is now active!');
    // 1. Register Commands
    const disposable = vscode.commands.registerCommand('agentInit.initialize', async () => {
        // Manual Trigger
        const ui = new ui_controller_1.UIController(context);
        const workspaceFolders = vscode.workspace.workspaceFolders;
        if (!workspaceFolders) {
            ui.showErrorMessage('No workspace open.');
            return;
        }
        // For manual trigger, we can pick the first one or ask user. 
        // MVP: Pick first.
        const folder = workspaceFolders[0];
        await performInitialization(folder, ui);
    });
    const checkStatusDisposable = vscode.commands.registerCommand('agentInit.checkStatus', () => {
        vscode.window.showInformationMessage('Agent Init: Status Check');
    });
    context.subscriptions.push(disposable);
    context.subscriptions.push(checkStatusDisposable);
    // 2. Initialize Watcher (Automatic Detection)
    const watcher = new watcher_1.WatcherService();
    const ui = new ui_controller_1.UIController(context);
    watcher.watch(context, async (folder) => {
        console.log(`Agent Init: Standards missing in ${folder.name}`);
        const shouldInit = await ui.showInitializePrompt();
        if (shouldInit) {
            await performInitialization(folder, ui);
        }
    });
    console.log('Agent Init: Detection Watcher Active');
}
async function performInitialization(folder, ui) {
    const github = new github_client_1.GitHubClient();
    const fileHandler = new file_handler_1.FileHandler();
    try {
        ui.showSuccessMessage('Agent Init: Fetching templates...');
        const template = await github.fetchTemplate({
            owner: 'irahardianto',
            repo: 'antigravity-setup',
            branch: 'main'
        });
        await fileHandler.writeFiles(folder.uri, template.files);
        ui.showSuccessMessage('Agent Init: AI Standards initialized successfully!');
    }
    catch (error) {
        const msg = error instanceof Error ? error.message : String(error);
        ui.showErrorMessage(`Initialization Failed: ${msg}`);
        console.error('Agent Init Error:', error);
    }
}
function deactivate() {
    // Clean up resources
}

})();

var __webpack_export_target__ = exports;
for(var __webpack_i__ in __webpack_exports__) __webpack_export_target__[__webpack_i__] = __webpack_exports__[__webpack_i__];
if(__webpack_exports__.__esModule) Object.defineProperty(__webpack_export_target__, "__esModule", { value: true });
/******/ })()
;
//# sourceMappingURL=extension.js.map